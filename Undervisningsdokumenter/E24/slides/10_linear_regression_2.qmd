---
format: 
  revealjs:
    theme: css_etc/custom-theme-ilisimatusarfik.css
    slide-level: 0
    incremental: false 
    logo: css_etc/ilisimatusarfik.png
    highlight: true
    highlight-style: github-dark
    autoStretch: true
    self-contained: false
    preload-iframes: true
editor: visual
---

::: center
# LineÃ¦r regression

### Statistik E24 (15 ECTS)

### ved Mikkeline Munk Nielsen
:::

------------------------------------------------------------------------

## Program

<br>

-   Diskrete variable i lineÃ¦r regressionsanalyse

-   Kodning af dummy-variable

-   ForlÃ¦ns modelsÃ¸gning

------------------------------------------------------------------------

## LineÃ¦r regression recap

Sidst arbejde vi med en simpel lineÃ¦r regressionsmodel med en afhÃ¦ngig variabel ğ‘Œ og en uafhÃ¦ngig variabel ğ‘‹:

\
$$Y=\alpha + \beta*X+\epsilon$$

Og en multiple lineÃ¦r regressionsmodel, hvor vi tilfÃ¸jede en kontrolvariabel ğ‘:

$$Indkomst = \alpha+\beta*X+\delta* Z+\epsilon$$

------------------------------------------------------------------------

## LineÃ¦r regression recap

I den simple lineÃ¦r regressionsmodel undersÃ¸ger vi sammenhÃ¦ngen mellem ğ‘Œ og ğ‘‹. Parameteret ğ›½ beskriver den ubetingede lineÃ¦re sammenhÃ¦ng mellem dem:

\
$$Y=\alpha + \beta*X+\epsilon$$

I den multiple lineÃ¦r regressionsmodel undersÃ¸ger vi om sammenhÃ¦ngen mellem ğ‘Œ og ğ‘‹ bestÃ¥r, nÃ¥r vi tager hÃ¸jde for et tredje forhold ğ‘.

$$Indkomst = \alpha+\beta*X+\delta* Z+\epsilon$$

Parameteret ğ›½ beskriver nu den betingede lineÃ¦re sammenhÃ¦ng mellem dem ğ‘Œ og ğ‘‹, nÃ¥r vi kontrollerer for ğ‘.

------------------------------------------------------------------------

## LineÃ¦r regression recap

$$Indkomst = \alpha+\beta*uddannelse+\delta* alder+\epsilon$$

SummeÃ¸velse 10 min: hvad er fortolkningen af fÃ¸lgende parametre (og fejlledet)?

$\alpha$:

$\beta$:

$\delta$:

$\epsilon$:

------------------------------------------------------------------------

## LineÃ¦r regression recap

$$Indkomst = \alpha+\beta*uddannelse+\delta* alder+\epsilon$$

SummeÃ¸velse 10 min: hvad er fortolkningen af fÃ¸lgende parametre (og fejlledet)?

$\alpha$: Den gennemsnitlige indkomst, nÃ¥r antal Ã¥rs uddannelse = 0 og alder = 0

$\beta$: den gennemsnitlige Ã¦ndring i indkomst, hver gang antal Ã¥rs uddannelse stiger med 1 (kontrolleret for alder)

$\delta$: den gennemsnitlige Ã¦ndring i indkomst, hver gang alder stiger med 1 (kontrolleret for antal Ã¥rs uddannelse)

$\epsilon$: den gennemsnitlige afvigelse mellem respondenternes observerede indkomst og den indkomst, som regressionsmodellen forudsiger, at respondenten har, pÃ¥ baggrund af ğ›¼ og ğ›½

------------------------------------------------------------------------

## LineÃ¦r regression recap

<br>

Indtil videre har vi slet ikke talt om variablenes mÃ¥leniveau i lineÃ¦r regression... Det laver vi om pÃ¥ nu!

------------------------------------------------------------------------

## MÃ¥leniveauer i lineÃ¦r regression

Den ***afhÃ¦ngige*** variabel ğ‘Œ er altid kontinuert (intervalskaleret)

$$Y= \alpha+\beta*X+\delta* Z+\epsilon$$

***UafhÃ¦ngige*** variable (herunder kontrolvariable) kan bÃ¥de vÃ¦re kontinuerte og diskrete (altsÃ¥ bÃ¥de intervalskalerede, nominelle eller ordinale)

<br>

Principielt er der ingen forskel i fortolkningen af koefficienter for hhv. kontinuerte og diskrete variable. Koefficienter beskriver altid Ã¦ndringen i ğ‘Œ for Ã©n enhedsÃ¦ndring i ğ‘‹. Men i praksis er der en forskel...

------------------------------------------------------------------------

## MÃ¥leniveauer i lineÃ¦r regression

-   Diskrete variable kodes som binÃ¦re â€dummy variableâ€, der kun kan tage vÃ¦rdien 0 eller 1

-   En dummy for kÃ¸n kan f.eks. laves til en ny variabel â€kvindeâ€, der antage vÃ¦rdien 1, hvis respondenten er en kvinde, og vÃ¦rdien 0, hvis respondenten er en mand.

$$Y= \alpha+\beta*Kvinde+\epsilon$$

Her vil ğ›½ beskrive Ã¦ndringen i indkomst, hvis variablen â€kvindeâ€ gÃ¥r fra 0 (mand) til kvinde (1).

------------------------------------------------------------------------

## MÃ¥leniveauer i lineÃ¦r regression

Vi kan dermed regne os frem til den forventede indkomst for hhv. mÃ¦nd og kvinder:

$Indkomst= \alpha+\beta*Kvinde+\epsilon$

MÃ¦nd:

$Indkomst_{mand}= \alpha+\beta*0+\epsilon$

$Indkomst_{mand}= \alpha+\epsilon$

Kvinder:\
$Indkomst_{kvinde}= \alpha+\beta*1+\epsilon$

$Indkomst_{kvinde}= \alpha+\beta+\epsilon$

------------------------------------------------------------------------

## MÃ¥leniveauer i lineÃ¦r regression

Med andre ord vil konstantleddet ğ›¼ reprÃ¦sentere den forventede vÃ¦rdi pÃ¥ Y, nÃ¥r dummy variablen = 0.

$$Indkomst= \alpha+\beta*Kvinde+\epsilon$$

Det er prÃ¦cis ligesom med kontinuerte variable. Konstantleddet ğ›¼ reprÃ¦senterer altid den forventede vÃ¦rdi pÃ¥ den afhÃ¦ngige variabel Y, nÃ¥r alle uafhÃ¦ngige variable = 0.

------------------------------------------------------------------------

## MÃ¥leniveauer i lineÃ¦r regression

-   For diskrete variable med mere end to kategorier kodes hver kategori ogsÃ¥ til sin egen dummy variabel

-   Tag f.eks. en nominel variabel der mÃ¥ler ens persons ansÃ¦ttelsestype i tre kategorier, lÃ¸nmodtager, selvstÃ¦ndig eller hjemmegÃ¥ende (familie):

    $$
    \Omega{=LÃ¸nmodtager, selvstÃ¦ndig, familie}
    $$

-   Disse tre kategorier laves til hver sin dummy variabel

$$
X_1 = lÃ¸nmodtager, X_2=selvstÃ¦ndig, X_3 = familie
$$

------------------------------------------------------------------------

## Dummy fÃ¦lden

-   Her opstÃ¥r dog et problem! En respondent er enten lÃ¸nmodtager, selvstÃ¦ndig eller arbejder i familien. Man kan altsÃ¥ kun have vÃ¦rdien 1 pÃ¥ Ã¨n af de tre variable.

$$
X_1 = lÃ¸nmodtager, X_2=selvstÃ¦ndig, X_3 = familie
$$

-   I praksis betyder dette, at man er nÃ¸d til at udelade en af kategorierne/dummierne fra sin regressionsmodel. Ellers kommer man i problemer med noget der hedder multikollinaritet! Det vender vi tilbage til...

-   Af samme Ã¥rsag kan man heller ikke bÃ¥de have en mand og en kvinde dummy i samme model.

------------------------------------------------------------------------

## Dummy fÃ¦lden

$X_1 = lÃ¸nmodtager, X_2=selvstÃ¦ndig, X_3 = familie$

<br>

Regressionsmodellen kommer til at se sÃ¥ledes ud, nÃ¥r vi udelukker $X_1 = lÃ¸nmodtager$

$Y=\alpha+\beta_1*X_2+\beta_2*X_3+\epsilon$

$Y=\alpha+\beta_1*selvstÃ¦ndig+\beta_2*familie+\epsilon$

<br>

I denne model vil den udeladte kategori $X_1 = lÃ¸nmodtager$ ende med at ligge i konstantleddet $\alpha$

Det giver mening, fordi ğ›¼ altid mÃ¥ler den gennemsnitlige vÃ¦rdi pÃ¥ ğ‘Œ, nÃ¥r vÃ¦rdien pÃ¥ alle ğ‘‹Â´er = 0. Hvis man har vÃ¦rdien 0 pÃ¥ bÃ¥de ğ‘‹1 (selvstÃ¦ndig) og ğ‘‹2 (familie), sÃ¥ er det fordi, at man har vÃ¦rdien 1 pÃ¥ den udeladte kategori ğ‘‹3 (lÃ¸nmodtager).

------------------------------------------------------------------------

## Dummy fÃ¦lden

$X_1 = lÃ¸nmodtager, X_2=selvstÃ¦ndig, X_3 = familie$

<br>

Regressionsmodellen kommer til at se sÃ¥ledes ud, nÃ¥r vi udelukker $X_1 = lÃ¸nmodtager$

$Y=\alpha+\beta_1*X_2+\beta_2*X_3+\epsilon$

$Y=\alpha+\beta_1*selvstÃ¦ndig+\beta_2*familie+\epsilon$

<br>

Fortolkningen af parametrene i modellen er dermed:

$\alpha$: den forventede indkomst for en lÃ¸nmodtager (den udeladte kategori)

$\beta_1$: forskellen i den forventede lÃ¸n fra referencekategorien ğ›¼ (lÃ¸nmodtager) til selvstÃ¦ndige

$\beta_2$: forskellen i den forventede lÃ¸n fra referencekategorien ğ›¼ (lÃ¸nmodtager) til at arbejde i familien

------------------------------------------------------------------------

## Dummy fÃ¦lden

<br>

Hvis man glemmer at udelukke en kategori gÃ¥r man i den sÃ¥kaldte â€dummy-fÃ¦ldeâ€.

<br>

HVIS I gÃ¸r det... SÃ¥ smider R selv en kategori ud.

------------------------------------------------------------------------

## Kodning af dummy-variable

Princippet med dummier er, at man konstruerer en binÃ¦r variabel for hver kategori pÃ¥ en disktret variabel. Disse binÃ¦re variable tager enten vÃ¦rdien 0 eller 1. En variabel for kÃ¸n med to kategorier, Mand og Kvinde, kodes til to nye variable:

-   Mand

-   Kvinde

Respondenter med vÃ¦rdien â€œKvindeâ€ pÃ¥ den oprindelige variabel kÃ¸n, tager vÃ¦rdien 1 pÃ¥ den nye variable Kvinde. MÃ¦nd tager vÃ¦rdien 0. Det omvendte gÃ¦lder, pÃ¥ variablen Mand.

------------------------------------------------------------------------

## Kodning af dummy-variable

FÃ¸r vi laver dummier af en diskret variabel, skal vi danne os et overblik over dens kategorier. Start derfor med at lave en tabel over kategorierne pÃ¥ variablen:

```{r include=F}
df <- readRDS("C:/Users/mmn/Dropbox/Ilisimatusarfik/Undervisningsdokumenter/E24/slides/data/ESS.rds") 

library(tidyverse)
df <- df %>% filter(land=="DK") %>% select(koen, udd, net_indkomst, alder, antal_timer_arb) %>% na.omit()
```

```{r echo=TRUE, warning=F, message=F}
library(janitor)

tabyl(df$koen)
```

------------------------------------------------------------------------

## Kodning af dummy-variable

Variablen har to kategorier, â€œMandâ€ og â€œKvindeâ€. Vi konstruerer derfor to nye variable - Ã©n for hver kategori pÃ¥ den oprindelige variabel - og tilfÃ¸jer dem til datasÃ¦ttet. Vi bruger funktionerne `mutate()` og `ifelse()` til omkode og/eller at skabe nye variable og tilfÃ¸je dem til datasÃ¦ttet.

```{r echo=TRUE, warning=F, message=F}
library(dplyr)
df <- df %>% mutate(
mand = ifelse(koen=="Mand",1,0),
kvinde = ifelse(koen=="Kvinde",1,0))
```

Vi har nu tilfÃ¸jet to dummy-variable til datasÃ¦ttet:

```{r echo=TRUE, warning=F, message=F}
df %>% select(koen, mand, kvinde) %>% head
```

------------------------------------------------------------------------

## Ã˜velse i dummy-variable

Ã…ben ESS datasÃ¦ttet og kod dummy-variable for variablen `udd`

```{r}
tabyl(df$udd)
```

<br>

EstimÃ©r derefter fÃ¸lgende regressionsmodel:

$Indkomst=\alpha+\beta_1*{ungdoms\_erhvervsudd}+\beta_2*{ml\_videregÃ¥ende}+\beta_3*{lang\_videregÃ¥ende}+\epsilon$

<br>

Giv fortolkning pÃ¥ parametrene: $\alpha, \beta_1, \beta_2,\beta_3$

------------------------------------------------------------------------

## Ã˜velse i dummy-variable

```{r echo=F, warning=F, message=F}
library(tidyverse)

df <- df %>% mutate(
grundskole = ifelse(udd=="Grundskole",1,0),
ung_erhv = ifelse(udd=="Ungdoms-/erhvervsuddannelse",1,0),
ml_vid = ifelse(udd=="Mellemlang videregÃ¥ende",1,0),
lang_vid = ifelse(udd=="Lang videregÃ¥ende",1,0))
```

---

## Ã˜velse i dummy-variable

```{r echo=TRUE, warning=F, message=F}
model <- lm(net_indkomst ~ ung_erhv + ml_vid+lang_vid, data=df)

library(texreg)
(texreg::screenreg(list(model), include.ci=F))
```

---

## ForlÃ¦ns modelsÃ¸gning

I lineÃ¦r regressionsanalyse har vi derfor typisk Ã©n hovedsammenhÃ¦ng, som vi fokuserer pÃ¥. SammenhÃ¦ngen mellem Ã©t enkelt ğ‘‹ og et ğ‘Œ

\
$$Y=\alpha + \beta*X+\epsilon$$

Herefter tilfÃ¸jer vi gradvist kontrolvariable for at forsÃ¸ge at forklare den simple lineÃ¦re sammenhÃ¦ng mellem ğ‘‹ og ğ‘Œ:

$Indkomst = \alpha+\beta_1X_1+\beta_2X_2+\beta_3X_3\epsilon$

$Indkomst = \alpha+\beta_1X_1+\beta_2X_2+\beta_3X_3+\beta_4X_4\epsilon$

Denne metode kaldes forlÃ¦ns modelsÃ¸gning. Pointen er, at fokusere pÃ¥ Ã¦ndringer i koefficienten for $\beta_1$ fra model til model.

------------------------------------------------------------------------

## ForlÃ¦ns modelsÃ¸gning

$$Indkomst = \alpha+\beta_1X_1+\beta_2X_2+\beta_3X_3+\beta_4X_4\epsilon$$

<br>

-   Hvis der er en sammenhÃ¦ng mellem $X_1$ og kontrolvariabel $X_2$, sÃ¥ vil koefficienten af $X_1$ Ã¦ndre sig, nÃ¥r $X_2$ inkluderes i modellen.

-   Ã†ndringen i $X_1$ kan tilskrives den del af sammenhÃ¦ngen mellem $X_1$ og $Y$ som forklares af $X_2$. Det samme gÃ¦lder for $X_3$ og $X_4$ osv.

------------------------------------------------------------------------

## Sammenligning af modeller

<br>

-   NÃ¥r vi har afprÃ¸vet flere forskellige modeller vil vi gerne kunne sige noget om, hvilken model der er bedst.

-   I lineÃ¦r regressionsanalyser bruger man determinationskoefficienten ğ‘…2 til at mÃ¥le pÃ¥ en models â€forklaringskraftâ€

-   ğ‘…2 udtrykker andelen af variation i den afhÃ¦ngige variabel Y, der kan forklares af den eller de uafhÃ¦nige variable Lad os lige gennemgÃ¥ for forstÃ¥elsens skyld, hvordan den udregnes...

------------------------------------------------------------------------

## Forklaringskraft

::::: two-column-layout
::: left-column
LineÃ¦r regression â€fitterâ€ den linje, som minimerer den samlede afstand til datapunkterne

PÃ¥ engelsk kaldes metoden â€OLSâ€. Det stÃ¥r for Ordinary Least Squares eller mindste kvadraters metode

Det hedder mindste kvardraters metode, fordi linjes lÃ¦gges der, hvor summen af de kvardrerede afstande til datapunkterne er mindst
:::

::: right-column
![](images/MSS.png)
:::
:::::

------------------------------------------------------------------------

## Forklaringskraft

Man skelner mellem:

::::: two-column-layout
::: left-column
-   [Total sum of squares (TSS):]{.underline}\
    Summen af afstanden fra de observerede vÃ¦rdier til middelvÃ¦rdien $\sum(y_i-\bar{y})^2$

-   [Estimated sum of squares (ESS):]{.underline}\
    Summen af afstanden fra de forudsagte vÃ¦rdier til middelvÃ¦rdien $\sum(\hat{y}-\bar{y})^2$

-   [Residual sum of squares (RSS)]{.underline}\
    Summen af afstanden fra de observerede vÃ¦rdier til de forudsagte vÃ¦rdier (summen af residualerne $\sum(y_i-\hat{y})^2$
:::

::: right-column
![](images/TSS.png)
:::
:::::

---

## Forklaringskraft

<br>

-   **Total sum of squares (TSS):** *den totale varians pÃ¥ Y*

-   **Estimated sum of squares (ESS):** *den forklarede del af variansen pÃ¥ Y*

-   **Residual sum of squares (RSS):** *den uforklarede del af variansen pÃ¥ Y*

---

## Forklaringskraft

<br>

-   Som sagt udtrykke ğ‘…2 vÃ¦rdien andelen af variation i den afhÃ¦ngige variabel Y, der kan forklares af modellens uafhÃ¦ngige variable

-   Den er givet ved: $$R^2 = ESS/TSS$$

-   Den uforklarede del ligger i fejlledene og opsummeres af RSS

---

## Forklaringskraft

texreg printer $R^2$ vÃ¦rdien for jer nederst i regressionstabellen:

```{r warning=F, message=F}
model1 <- lm(net_indkomst ~ koen, data = df)
model2 <- lm(net_indkomst ~ koen + antal_timer_arb, data = df)
model3 <- lm(net_indkomst ~ koen + antal_timer_arb + ung_erhv + ml_vid+lang_vid, data=df)

library(texreg)
(texreg::screenreg(list(model1, model2, model3), include.ci=F))
```

$ğ‘…^2$ vÃ¦rdien pÃ¥ 0,31 betyder, at de uafhÃ¦ngige variable kan forklare ca. 31 % af variationen pÃ¥ den afhÃ¦ngige variabel

---

## Forklaringskraft

I kan bruge $ğ‘…^2$ til at sammenligne modeller i forlÃ¦ns modelsÃ¸gning for at se, hvilken model der ser ud til at forklare mest af variationen i Y:

Model 1: $Indkomst=\alpha+\beta_1*kvinde+\epsilon$

Model 2: $Indkomst=\alpha+\beta_1*kvinde+\beta_2*antal\_arbejdstimer+\epsilon$

Model 3: $Indkomst=\alpha+\beta_1*kvinde+\beta_2*antal\_arbejdstimer+\beta_3*ung\_erhv+\beta_4*ml\_vid+\beta_5*lang\_vid+\epsilon$

<br>

Men I kan ogsÃ¥ teste, om en model forklarer signifikant mere, end en anden model!

---

## Test til sammenligning af modeller 

NÃ¥r man skal sammenligne to modeller med kun Ã©t parameter til forskel, sÃ¥ er det nok at kigge pÃ¥ t-testen for det pÃ¥gÃ¦ldende parameter (aflÃ¦se p-vÃ¦rdien eller stjerner\*\*\* for parametret)

Model 1: $Indkomst=\alpha+\beta_1*kvinde+\epsilon$

Model 2: $Indkomst=\alpha+\beta_1*kvinde+\beta_2*antal\_arbejdstimer+\epsilon$

<br>

Hvis $\beta_2$ er signifikant vil model 2 forklare signifikant mere end model 1, fordi der er en signifikant sammenhÃ¦ng mellem indkomst og antal Ã¥rs uddannelse.

Antal Ã¥rs uddannelse ser altsÃ¥ ud til at forklare noget af variationen i indkomst!

---

## Test til sammenligning af modeller 

Hvis der er mere end et enkelt parameter til forskel pÃ¥ to modeller, kan I ikke nÃ¸jes med t-testen pÃ¥ de nye parametre.

<br>

[Model 2:]{.underline}\
$Indkomst=\alpha+\beta_1*kvinde+\beta_2*antal\_arbejdstimer+\epsilon$

[Model 3:]{.underline}

$Indkomst=\alpha+\beta_1*kvinde+\beta_2*antal\_arbejdstimer+\beta_3*ung\_erhv+\beta_4*ml\_vid+\beta_5*lang\_vid+\epsilon$

<br>

I stedet skal I lave en F-test for at teste, om den forklaringskraft, som flere variable tilsammen tilfÃ¸jer, er signifikant forskellig fra 0. Dette er sÃ¦rligt relevant med dummy variable, hvor hver kategori jo har hvert sit parameter!

---

## F-test for to modeller

<br>

[Hypoteserne i F-testen er:]{.underline}

**H0**: Forklaringskraften i model 3 er ikke hÃ¸jere end i model

**H1**: Forklaringskraften i model 3 er hÃ¸jere end i model

<br>

Hvis p-vÃ¦rdien er under 0,05 forkastes nulhypotesen, og vi konkluderer, at model 3 har en signifikant hÃ¸jere forklaringskraft model 2.

Hvis p-vÃ¦rdien er over 0,05, kan vi ikke med 95 % sikkerhed sige, at forklaringskraften i model 3 er bedre end i model 2.

---

## F-test for to modeller

I R estimeres F-testen mellem to modeller via funktionen `anova()`

```{r echo=TRUE, warning=F, message=F}
f_test <- anova(model2, model3)

(f_test_summary <- data.frame(
  "Forskel i Frihedsgrader" = f_test$Df[2],        # Forskel i frihedsgrader
  "F-statistik" = f_test$F[2],                     # F-statistik
  "P-vÃ¦rdi" = sprintf("%.4f", f_test$`Pr(>F)`[2]), # P-vÃ¦rdi med 4 decimaler
  check.names = FALSE))
```

P-vÃ¦rdien bruges som altid til at konkludere, om nulhypotesen kan forkastes
