---
format:
  revealjs:
    theme: css_etc/custom-theme-ilisimatusarfik.css
    slide-level: 0  # Disable automatic slide creation from headings
    incremental: false
    logo: css_etc/ilisimatusarfik.png
    highlight: true
    highlight-style: github-dark
editor: visual
---

::: center
# Hypotesetestning

### Statistik E24 (15 ECTS)

### ved Mikkeline Munk Nielsen
:::

------------------------------------------------------------------------

# Hvad er hypotesetestning?

-   Hypotesetest er en statistisk procedure designet til at evaluere hypoteser/p√•stande om en populations egenskaber baseret p√• stikpr√∏vedata

-   Eksempel p√• hypotese: der er forskel p√• gennemsnitsl√∏nnen for m√¶nd og kvinder i Gr√∏nland

-   Form√•l: At tr√¶ffe beslutninger om, hvorvidt der er tilstr√¶kkeligt bevis for at afvise hypotesen med udgangspunkt i stikpr√∏ven

-   Konkret bruger vi dem til at vurdere, om forskelle og observationer vi ser i vores stikpr√∏ve er tilf√¶lde pga. stikpr√∏veusikkerhed, eller om det er sandsynligt, at de er udtryk for rigtige forskelle i populationen

------------------------------------------------------------------------

# Fremgangsm√•de

I hypotesetests stiller man to hypoteser op og tester dem mod hinanden:

-   ***Nulhypotese (H0)***: En p√•stand om, at der ikke er nogen signifikant forskel eller virkning.

-   ***Alternativ hypotese (H1)***: En p√•stand om, at der er en signifikant forskel eller virkning.

[Eksempel]{.underline}:

**H0**: Der er [ikke]{.underline} nogenforskel i gennemsnitsl√∏nnen for m√¶nd og kvinder

**H1**: Der [er]{.underline} forskel i gennemsnitsl√∏nnen for m√¶nd og kvinder

------------------------------------------------------------------------

# Fremgangsm√•de

1.  **Formulering af hypoteser:** Formulering af nulhypotese og alternativ hypotese
2.  **Valg af signifikansniveau:** Fastl√¶ggelse af den sandsynlighed vi har defineret i konfidensintervallet som den acceptable usikkerhed.
3.  **Beregning af teststatistik**: Anvendelse af passende statistisk test til at beregne teststatistikken baseret p√• stikpr√∏vedataene.
4.  **Afg√∏relse**: Sammenligning af teststatistikken med en kritisk v√¶rdi eller p-v√¶rdi for at afg√∏re, om man skal afvise nulhypotesen.

------------------------------------------------------------------------

# Hvordan evalueres hypoteser?

-   Man evaluerer hypoteserne vil at udregne en test-statistik

-   En teststatistik er en beregning, der opsummerer informationen fra dine data for at vurdere, hvor meget de afviger fra det, vi forventer under nullhypotesen (H0‚Äã).

-   Test-statistikken er det tal, som vi bruger til at tr√¶ffe en beslutning om, hvorvidt dataene underst√∏tter H0‚Äã eller H1‚Äã.

------------------------------------------------------------------------

# Udregning af test-statistikker

Beregningen f√∏lger altid en grundl√¶ggende struktur:

$$
\text{Teststatistik} = \frac{\text{observeret forskel/fordeling} - \text{forventet forskel/fordeling under } H_0}{\text{standardfejl}}
$$

-   **Observeret forskel/fordeling**: Hvad ser vi i data? For eksempel en forskel mellem to grupper eller en sammenh√¶ng mellem to variabler

-   **Forventet forskel/fordeling under (H0)**: Hvad forventer vi, hvis H0 er sand? Ofte er dette ingen forskel eller effekt (dvs. 0).

-   **Standardfejl**: Et m√•l for, hvor meget forskelle i data kan forventes at variere tilf√¶ldigt (som resultat af at have trukket en stikpr√∏ve)

------------------------------------------------------------------------

# Udregning af test-statistikker

For normalfordelte variable kan vi standardisere den observerede forskel til en **z-score**:

$$ z = \frac{\text{observeret forskel} - \text{forventet forskel under } H_0}{\text{standardfejl}} $$

**Hvad fort√¶ller z-scoren?**

-   z-scoren viser, hvor mange standardafvigelser den observerede forskel er v√¶k fra det forventede under (H0).

-   Jo h√∏jere (z)-score (positiv eller negativ), desto l√¶ngere v√¶k fra middelv√¶rdien ligger dataene.

-   For at evaluere resultatet af en test placeres teststatistikken p√• en teoretisk fordeling, der repr√¶senterer, hvordan teststatistikken ville fordele sig, hvis nulhypotesen (H0) er sand. Dette g√∏r det muligt at vurdere, om den observerede teststatistik er ekstrem nok til at afvise H0.

------------------------------------------------------------------------

# Udregning af test-statistikker

N√•r vi beregner en z-score, placerer vi resultatet p√• standard-normalfordelingens x-akse:

-   $z=0$: Data ligger pr√¶cis p√• middelv√¶rdien, som forventet under‚Äã.

-   $z>0$: Data ligger over middelv√¶rdien.

-   $z<0$: Data ligger under middelv√¶rdien.

-   Jo l√¶ngere v√¶k z-scoren er fra $0$, desto mere ekstreme er dataene:

Fx: $z=2$ betyder, at data ligger **2 standardafvigelser v√¶k** fra middelv√¶rdien.

------------------------------------------------------------------------

# Udregning af test-statistikker

-   Vi ved, at afstanden fra en observeret v√¶rdi til middelv√¶rdien i en normalfordeling fort√¶ller os, hvor ***sandsynligt*** det er at observere en given v√¶rdi

-   Vi ved ogs√• fra standardnormalfordelingen, at der er 95 % sandsynlighed for at observere en v√¶rdi der ligger $\pm 1,96$ standardafvigelser omkring stikpr√∏vegennemsnittet.

-   Dermed kan vi p√• baggrund af afstanden fra en observeret v√¶rdi til gennemsnittet (under H0) udregne, hvor sansynligt det er at observere v√¶rdien

-   P√• samme m√•de kan vi i hypotesetests fastl√¶gge en ***kritisk v√¶rdi***, hvor sandsynligheden for at observere en v√¶rdi s√• ekstrem (eller mere ekstrem) er s√• lille, at vi ikke l√¶ngere tror p√•, at det bare kan skyldes tilf√¶ldigheder.

------------------------------------------------------------------------

# Kritiske v√¶rdier i normalfordelingen

![](images/standardnormalfordeling.png){fig-align="center"}

------------------------------------------------------------------------

# Evaluering af hypotesetest

Hvis vi f√•r en test-statistik, der ligger over den kritiske v√¶rdi siger vi, at forskellen er statistisk signifikant! Dvs. den forskel vi har observeret i stikpr√∏ven er ekstrem nok til, at vi tror p√•, at den kan genfindes i populationen - den er ikke bare tilf√¶ldig!

<br>

-   Hvis teststatistikken overskrider den kritiske v√¶rdi, **afvis** $H_0$‚Äã

-   Hvis teststatistikken ligger inden for intervallet af $\pm$ den kritiske v√¶rdi kan $H_0$ **ikke** **afvises**

------------------------------------------------------------------------

# Fejltyper i hypotesetest

N√•r man tester statistiske hypoteser, kan man beg√• to typer af fejl:

-   **Type I**: Fejlagtigt forkaste $H_0$, n√•r $H_0$ faktisk er sand.
-   **Type II**: Fejlagtigt acceptere $H_0$, n√•r $H_1$ faktisk er sand.

[**Definitioner**:]{.underline}

-   $P(\text{fejl af Type I}) = \alpha$: Sandsynligheden for at beg√• en type I-fejl (signifikansniveauet).
-   $P(\text{fejl af Type II}) = \beta$: Sandsynligheden for at beg√• en type II-fejl.

*Bem√¶rk: Lav* $\alpha$ reducerer risikoen for Type I-fejl, men kan √∏ge risikoen for Type II-fejl

------------------------------------------------------------------------

# Nulhypotese og alternativ hypotese:

En mand stilles for en dommer, anklaget for noget kriminelt.

-   $H_0$: Manden er **ikke skyldig**.
-   $H_1$: Manden **er skyldig**.

[Mulige fejltyper:]{.underline}

-   **Type I**: Manden er uskyldig, men d√∏mmes skyldig *(Sandsynlighed:* $p = \alpha$)

-   **Type II**: Manden er skyldig, men frikendes*(Sandsynlighed:* $p = \beta$)

**Bem√¶rk**:\
$\alpha$ er signifikansniveauet ‚Äì alts√• den sandsynlighed, vi har defineret som den acceptable risiko for fejlagtigt at forkaste $H_0$.

------------------------------------------------------------------------

# Statistisk signifikans

-   Signifikans er et vigtigt begreb i hypotesetests, og relaterer sig tilbage til statistisk usikkerhed.

-   F√∏r en hypotesetest fasts√¶ttes det acceptable niveau af statistisk usikkerhed, nemlig sandsynligheden for at afvise nulhypotesen, hvis den er sand (type I fejl).

-   Man arbejder typisk med ùõº=0,05 dvs. 5 % sandsynlighed for at beg√• type I fejl

------------------------------------------------------------------------

# P-v√¶rdier og signifikans

I praksis bruges p-v√¶rdier til at vurdere p√• hypotesetests:

-   En $p$-v√¶rdi er sandsynligheden for at f√• en teststatistik, der er *lige s√• ekstrem eller mere ekstrem* end den observerede, givet at nulhypotesen H0 er sand.

-   Man sammenligner $p$ -v√¶rdien med signifikansniveauet $\alpha$ (fx $0,05$):

    -   Hvis $p < \alpha$, afvises H0 (statistisk signifikant).

    -   Hvis $p \geq \alpha$, kan H0 ikke afvises (ikke statistisk signifikant)

Hvis vores signifikansniveau er sat til $5%$% afviser vi nulhypotesen, hvis vores $p<0,05$. Hvis $p‚â•0,05$ kan vi ikke afvise nulhypotesen.

------------------------------------------------------------------------

# P-v√¶rdier og signifikans

Hvorfor bruger vi p-v√¶rdier i stedet for at sammenligne test-statistikker med kritiske v√¶rdier?

-   **Universel anvendelse**: $p$-v√¶rdier kan bruges p√• tv√¶rs af forskellige fordelinger ( $t$-, $z$-, $\chi^2$, osv.), uden at man manuelt skal sl√• kritiske v√¶rdier op.

-   **Grad af evidens**: $p$-v√¶rdien giver en pr√¶cis sandsynlighed, ikke kun en ja/nej-konklusion som ved kritiske v√¶rdier.

-   **Tydelig sammenligning**: Let at sammenligne testresultater, uanset hvilken test eller fordeling der bruges.

------------------------------------------------------------------------

# Tests og fordelinger

Forskellige statistiske fordelinger bruges i hypotesetestning afh√¶ngigt af datatypen, stikpr√∏vens st√∏rrelse og kendskab til populationens egenskaber:

-   **Normalfordeling** (z-test): Bruges til intervalskalerede variable, n√•r stikpr√∏ven er stor ($n>30$) og populationens standardafvigelse er kendt ($\sigma$)

-   **t-fordeling** (t-test): Bruges til intervalskalerede variable ved sm√• stikpr√∏ver eller ukendt standardafvigelse

-   **Chi-i-anden-fordeling**: Bruges ved kategoriske data (nominal og ordinal)

<br>

I praksis bruges t-testen for intervalskalerede variable, da vi sj√¶ldent kender $\sigma$ og bruger stikpr√∏vens standardafvigelse $s$ som estimat for $\sigma$. T-fordelingen n√¶rmer sig alligevel normalfordelingen som stikpr√∏ven √∏ges.

------------------------------------------------------------------------

# Hypotese-test i univariat analyse

I skal kende til to hypotesetests for univariat analyse (√©n variabel):

<br>

-   **T-test** (intervalskala variable): Tester, om et gennemsnit er forskelligt fra en specifik v√¶rdi, vi kender p√• forh√•nd.

-   <br>

-   $\chi^2$**-tes**t (nominal/ordinal): Bruges til at teste, om der er forskel p√• fordelingen af en nominal variabel i forhold til en forventet fordeling.

------------------------------------------------------------------------

# T-test for univariat analyse

I univariat analyse kan man anvende **t-testen** til formelt at teste, om gennemsnittet i en stikpr√∏ve er signifikant forskelligt fra en specifik v√¶rdi (f.eks. hvis du har viden om populationens sande gennemsnit):

<br>

[**Hypoteser:**]{.underline}

-   $H_0$: Stikpr√∏vegennemsnittet er lig populationens gennemsnit, $\bar{x} = \mu_0$
-   $H_1$: Stikpr√∏vegennemsnittet er forskelligt fra populationens gennemsnit, $\bar{x} \neq \mu_0$

------------------------------------------------------------------------

# T-test for univariat analyse

**Test-statistik**:

$$
t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}}
$$

Hvor:\
- $t$: Test-statistikken\
- $\bar{x}$: Stikpr√∏vegennemsnittet\
- $\mu_0$: Populationens gennemsnit (hvis kendt)\
- $s$: Standardafvigelsen i stikpr√∏ven\
- $n$: Antal observationer i stikpr√∏ven

------------------------------------------------------------------------

# T-test for univariat analyse

Teststatistikken $t$ angiver, hvor meget stikpr√∏vens gennemsnit afviger fra "den sande v√¶rdi" (populationens gennemsnit), udtrykt i forhold til usikkerheden p√• gennemsnittet.

-   Teststatistikken beregnes som: $$
    t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}}
    $$

-   Teststatistikken sammenlignes med en "kritisk v√¶rdi," som fastl√¶gges ud fra signifikansniveauet, man v√¶lger.

-   Den t-fordeling, som bruges til t-test, n√¶rmer sig normalfordelingen, n√•r $n > 30$. Derfor kan vi bruge vores viden om normalfordelingen til at udtale os om usikkerheden ved stikpr√∏vegennemsnittet ift. populationsgennemsnittet.

------------------------------------------------------------------------

# Kritiske v√¶rdier for t-fordelingen

| Frihedsgrader ($df$) | $\alpha = 0.10$ | $\alpha = 0.05$ | $\alpha = 0.01$ |
|----------------------|-----------------|-----------------|-----------------|
| 1                    | 12,706          | 6,314           | 63,657          |
| 5                    | 2,571           | 2,015           | 4,032           |
| 10                   | 1,812           | 1,812           | 3,169           |
| 20                   | 1,725           | 2,086           | 2,845           |
| 30                   | 1,697           | 2,042           | 2,750           |
| $\infty$ (stor $n$)  | 1,645           | 1,960           | 2,576           |

(Frihedsgrader: antal observationer - 1 for √©n stikpr√∏ve)

------------------------------------------------------------------------

# T-test for univariat analyse

-   Med et signifikansniveau p√• 5% vil den kritiske v√¶rdi i en t-fordeling v√¶re $¬±1,96$, fordi der er 95% sandsynlighed for at f√• en v√¶rdi, der ligger mellem $-1,96$ og $+1,96$ standardafvigelser fra gennemsnittet i en standardnormalfordeling

<br>

-   Hvis t-statistikken ligger udenfor $¬±1,96$ afvises$H_0$ og man konkluderer, at stikpr√∏vegennemsnittet er **signifikant anderledes** fra populationsgennemsnittet. Sandsynligheden for at observere en v√¶rdi (stikpr√∏vegennemsnit) der er s√• langt fra populationsgennemsnittet er nemlig kun 5 %, hvis nulhypotesen er sand.

<br>

-   Hvis t-statistikken ligger indenfor $-1,96$ og $+1,96$ kan vi ikke afvise$H_0$, da der ikke er tilstr√¶kkelig evidens til at afvise nulhypotesen. Forskellen mellem populations- og stikpr√∏vegennemsnit kan liges√• godt skyldes tilf√¶ldighed, da vi trak stikpr√∏ven.

------------------------------------------------------------------------

# T-test for univariat analyse

Alternativt kan vi bruge p-v√¶rdien til at konkludere p√• testen...

-   $p$-v√¶rdien angiver sandsynligheden for, at et nyt fors√∏g vil give en teststatistik, som er lige s√• usandsynlig (eller mere), under den antagelse, at nulhypotesen er sand.

-   Hvis vores signifikansniveau er sat til **5%**, afviser vi nulhypotesen, hvis $p < 0,05$.

-   Hvis $p \geq 0,05$, kan vi **ikke afvise nulhypotesen**. Dvs. vi ikke kan udelukke, at stikpr√∏vegennemsnittet er det samme som populationsgennemsnittet.

------------------------------------------------------------------------

# Eksempel: Gr√∏nlandske perspektiver

-   Gr√∏nlandske perspektiver survey (Ilisimatusarfik)

-   Foretaget i 13 gr√∏nlandske byer og bygder i alle Gr√∏nlands regioner i l√∏bet af sommeren 2018

-   Befolkning og politiske holdninger

------------------------------------------------------------------------

# Eksempel: T-test for univariat analyse

I R er t-testen utrolig nem med funktionen `t.test()` . Lad os pr√∏ve at teste, om gennemsnitsalderen for folk, der har besvaret GL-perspektiver surveyen er signifikant anderledes en tallet fra Gr√∏nlands statistik p√• 35,5 √•r:

<br>

**H0:** gennemsnitsalderen i surveyen er lige gennemsnitsalderen fra GL statistik $\bar{x}=\mu$

**H1:** gennemsnitsalderen i surveyen er signifikant anderledes end gennemsnitsalderen fra GL statistik $\bar{x}\ne\mu$

------------------------------------------------------------------------

# Eksempel: T-test for univariat analyse

-   Man inds√¶tter variabel (her `e5`, fra datas√¶ttet `df`) som stikpr√∏vegennemsnittet $\bar{x}$ regnes p√• og den forventede v√¶rdi $\mu$, som man gerne vil teste det p√•g√¶ldende gennemsnit op imod (ellers testes gennemsnittet mod $\mu=0$).

-   Her √∏nsker vi at teste mod aldersgennemsnittet fra populationen $\mu=35,5$:

```{r echo=T, warning=F, message=F}
df <- readRDS("Data/GL_perspektiver.rds")
t.test(df$e5, mu = 35.5)
```

------------------------------------------------------------------------

# Eksempel: T-test for univariat analyse

::: panel-tabset
### T-test

Resultaterne fra testen kan samles p√¶nere i en tabel:

```{r echo=F}
df <- readRDS("Data/GL_perspektiver.rds")

library(broom)
library(dplyr)

# K√∏r t-testen
test_result <- t.test(df$e5, mu = 35.5)

# Opret en data frame med de √∏nskede metrics i r√¶kker
(result_df <- data.frame(
  Parameter = c("Gennemsnit",                  # Gennemsnittet af pr√∏ven
             "Teststatistik",              # Teststatistikken (t-v√¶rdien)
             "P-v√¶rdi",                    # P-v√¶rdien med 4 decimaler
             "Nedre konfidensgr√¶nse",      # Nedre gr√¶nse for konfidensintervallet
             "√òvre konfidensgr√¶nse",       # √òvre gr√¶nse for konfidensintervallet
             "Frihedsgrader"),             # Frihedsgrader (df)
  V√¶rdi = c(
    round(test_result$estimate, 3),        # Gennemsnittet afrundet til 3 decimaler
    round(test_result$statistic, 3),      # Teststatistikken afrundet til 3 decimaler
    sprintf("%.3f", test_result$p.value), # P-v√¶rdi med 4 decimaler uden eksponentiel notation
    round(test_result$conf.int[1], 3),    # Nedre gr√¶nse afrundet til 3 decimaler
    round(test_result$conf.int[2], 3),    # √òvre gr√¶nse afrundet til 3 decimaler
    round(test_result$parameter, 1)       # Frihedsgrader afrundet til 1 decimal
  )
))
```

-   Eftersom p-v√¶rdien=0,000 (og alts√• mindre end 0,05) afviser vi nulhypotesen og konkluderer, at gennemsnitsalderen i denne stikpr√∏ve er signifikant anderledes end den i populationen.

-   Der er mindre end 0,000 % sandsynlighed for at observere dette stikpr√∏vegennemsnit (eller et mere ekstremt), hvis nulhypotesen er sand.

### Kode

```{r echo=T, eval=F}
library(broom)
library(dplyr)

# K√∏r t-testen
test_result <- t.test(df$e5, mu = 35.5)

# Opret en data frame med de √∏nskede metrics i r√¶kker
(result_df <- data.frame(
  Parameter = c("Gennemsnit",                 # Gennemsnittet af pr√∏ven
             "Teststatistik",              # Teststatistikken (t-v√¶rdien)
             "P-v√¶rdi",                    # P-v√¶rdien med 4 decimaler
             "Nedre konfidensgr√¶nse",      # Nedre gr√¶nse for konfidensintervallet
             "√òvre konfidensgr√¶nse",       # √òvre gr√¶nse for konfidensintervallet
             "Frihedsgrader"),             # Frihedsgrader (df)
  V√¶rdi = c(
    round(test_result$estimate, 3),        # Gennemsnittet afrundet til 3 decimaler
    round(test_result$statistic, 3),       # Teststatistikken afrundet til 3 decimaler
    sprintf("%.3f", test_result$p.value),  # P-v√¶rdi med 4 decimaler uden eksponentiel notation
    round(test_result$conf.int[1], 3),     # Nedre gr√¶nse afrundet til 3 decimaler
    round(test_result$conf.int[2], 3),     # √òvre gr√¶nse afrundet til 3 decimaler
    round(test_result$parameter, 1)        # Frihedsgrader afrundet til 1 decimal
  )
))
```
:::

------------------------------------------------------------------------

# Chi i anden test ($\chi^2$) for nominal- og ordinal-skalerede variable

-   Ordinal og nominalskalerede variable har ikke gennemsnit og varians uafh√¶ngigt af vores nummerering og derfor er disse meningsl√∏se. T-testen er derfor ogs√• meningsl√∏s.
-   I stedet tester vi, om fordelingen mellem variablens kategorier er forskellig fra en forventet fordeling.

**Goodness of fit**

-   Testen hedder œá¬≤ ‚Äì udtales 'Chi i anden' eller **goodness of fit**.
-   I œá¬≤-test for univariat hypotesetest kan vi teste **'goodness of fit'**, alts√• hvor t√¶t den observerede fordeling er p√• en forventet fordeling.

------------------------------------------------------------------------

# Chi i anden test ($\chi^2$) for nominal- og ordinal-skalerede variable

-   œá¬≤ fordeling opst√•r, n√•r vi antager, at en tilf√¶ldig variabel, der har *k* observationer ‚Äì kaldet **frihedsgrader** ‚Äì fordeler sig over et s√¶t af mulige udfald.
-   Hvis testen er **insignifikant**, er fordelingen **ikke med sikkerhed forskellig** fra den forventede fordeling.
-   Hvis testen er **signifikant**, er fordelingen **signifikant anderledes** end den forventede fordeling.

------------------------------------------------------------------------

# Chi i anden test ($\chi^2$) for nominal- og ordinal-skalerede variable

Hypoteser i univariat $\chi^2$ test (goodness of fit):

-   **H0**: Den observerede fordeling er ikke signifikant forskellig fra den forventede fordeling

-   **H1**: Den observerede fordeling er signifikant forskellig fra den forventede fordeling.Den observerede fordeling er signifikant forskellig fra den forventede fordeling.

------------------------------------------------------------------------

# Chi i anden test ($\chi^2$) for nominal- og ordinal-skalerede variable

Vi kan udregne test-statistikken og sammenligne den med den kritiske v√¶rdi i en œá-fordeling, denne fordeling er nemlig anderledes end normalfordelingen...

```{r echo=F}
# Load n√∏dvendige pakker
library(ggplot2)

# Defin√©r parametre
df <- 5  # Antal frihedsgrader
x_values <- seq(0, 20, by = 0.1)  # x-akse v√¶rdier (range for œá¬≤)

# Beregn t√¶thedsfunktion (density) for œá¬≤-fordelingen
density_values <- dchisq(x_values, df = df)

# Opret en data frame til ggplot
data <- data.frame(
  x = x_values,
  density = density_values
)

# Plot œá¬≤-fordelingen
ggplot(data, aes(x = x, y = density)) +
  geom_line(color = "#003366", size = 1.2) +  # Tegn t√¶thedskurven
  labs(
    x = bquote(chi^2),
    y = "T√¶thed"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16),  # Centr√©r titlen
    axis.title = element_text(size = 14)
  )
```

... Men vi kan ogs√• bare bruge p-v√¶rdien, som er sammenlignelig p√• tv√¶rs af alle tests. Nemt!

------------------------------------------------------------------------

# Eksempel: $\chi^2-test$ for univariat analyse

Variablen e5 m√•ler om respondenterne identificerer sig som v√¶rende gr√∏nlandsk, dansk, b√•de gr√∏nlandsk og dansk, eller andet:

```{r eval=F}
df <- readRDS("Data/GL_perspektiver.rds")
df <- df[df$e4 != "", ]
tabyl(df$e4)
```

Vi kan bruge $\chi^2$ goodness of fit testen til at teste, om fordelingen p√• variablen i stikpr√∏ven stemmer overens med en forventet fordeling.

------------------------------------------------------------------------

# Eksempel: $\chi^2-test$ for univariat analyse

De observerede v√¶rdier er antallet i hver kategori $(n)$, og den forventede fordeling er en sandsynlighedsfordeling $(p)$.

-   De observerede v√¶rdier fra tabellen er:

```{r}
observeret <- c(10, 61, 29, 538)
```

-   Antag en forventet fordeling som andele (5% andet, 10% gr√∏nlandsk og dansk, 5% dansk, 80% gr√∏nlandsk):

```{r}
forventet_andele <- c(0.05, 0.10, 0.05, 0.80)  # Din forventede fordeling
```

------------------------------------------------------------------------

# Eksempel: $\chi^2-test$ for univariat analyse

Brug funktionen `chisq.test()` for at sammenligne de observerede v√¶rdier med de forventede:

```{r}
chi_test <- chisq.test(x = observeret, p = forventet_andele)

# Print resultatet
print(chi_test)
```

------------------------------------------------------------------------

# Eksempel: $\chi^2-test$ for univariat analyse

Resultaterne kan samles p√¶nt i en tabel og eksporteres:

::: panel-tabset
### $\chi^2$-test

```{r echo=F}
(chi_table <- data.frame(
  Parameter = c("Chi-squared", "Degrees of Freedom", "p-value"),
  V√¶rdi = c(round(chi_test$statistic, 3),  # Chi-squared v√¶rdi
            chi_test$parameter,           # Frihedsgrader
            signif(chi_test$p.value, 3))  # p-v√¶rdi (signifikant til 3 decimaler)
))
```

Da p-v√¶rdien er under 0,05 kan vi forkaste nulhypotesen. Fordelingen af, hvad folk identificerer sig som er anderledes i stikpr√∏ven end i den forventede fordeling.

### Kode

```{r echo=T, eval=F}
# Saml resultaterne i en tabel
chi_table <- data.frame(
  Parameter = c("Chi-squared", "Degrees of Freedom", "p-value"),
  V√¶rdi = c(round(chi_test$statistic, 3),  # Chi-squared v√¶rdi
            chi_test$parameter,           # Frihedsgrader
            signif(chi_test$p.value, 3))  # p-v√¶rdi (signifikant til 3 decimaler)
)

library(writexl)
write_xlsx(list("Chi test" = chi_table), "Chi_tabel.xlsx")
```
:::

------------------------------------------------------------------------

# √òvelse

√Öben firmadatas√¶ttet og pr√∏v at estimer f√∏lgende:

-   Konfidensintervaller (95%) for variablen oms√¶tning

-   En t-test der tester, om det gennemsnitlige antal ansatte er signifikant forskellig fra 400

-   En chi-anden test (goodness of fit) der tester, om fordelingen p√• variablen indutri i datas√¶ttet er signifikant forskelligt fra en fordeling, som du selv ville forvente (defin√©r selv)

Husk at opstille hypoteser undervejs!
