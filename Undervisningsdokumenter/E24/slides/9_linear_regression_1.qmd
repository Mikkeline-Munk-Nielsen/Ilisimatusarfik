---
format: 
  revealjs:
    theme: css_etc/custom-theme-ilisimatusarfik.css
    slide-level: 0
    incremental: false 
    logo: css_etc/ilisimatusarfik.png
    highlight: true
    highlight-style: github-dark
    self-contained: false
    preload-iframes: true
editor: visual
---

::: center
# LineÃ¦r regression 1

### Statistik E24 (15 ECTS)

### ved Mikkeline Munk Nielsen
:::

------------------------------------------------------------------------

## Fra uni- til bi- til multivariat

<br>

**Univariat analyse**: analyser af fordelingen pÃ¥ Ã©n variabel

**Bivariat analyse**: analyse af sammenhÃ¦ngen mellem to variable

**Multivariat analyse**: analyser af sammenhÃ¦nge mellem to eller flere variable

<br>

LineÃ¦r regression hÃ¸rer under multivariat analyse.

------------------------------------------------------------------------

## Hvad var nu bivariat analyse?

Vi har ofte formodninger om bivariate sammenhÃ¦nge, f.eks. at uddannelsesniveau hÃ¦nger sammen med indkomst. Med den bivariate analyse kan vi afgÃ¸re:

-   Hvor sikker sammenhÃ¦ngen kan siges at vÃ¦re

-   Om sammenhÃ¦ngen er reel eller tilfÃ¦ldig

-   SammenhÃ¦ngens styrke og retning

------------------------------------------------------------------------

## To sider af bivariat analyse

<br>

-   **Den deskriptive (beskrivende) del**: at beskrive din stikprÃ¸ve.
    -   Fordelinger og fortolkning af krydstabeller/grafer mellem to variable.

    -   Korrelationskoefficienter â€“ sammenhÃ¦ngens styrke, retning og linearitet.

<br>

-   **Den analytiske del (inferens)**: at slutte fra stikprÃ¸ve til population.
    -   Hypotesetest â€“ fokus pÃ¥ om forskelle mellem to grupper er tilfÃ¦ldig eller sand.

------------------------------------------------------------------------

## Korrelationer

Korrelationer er et centralt begreb i statistik. De er et udtryk for samvariationen mellem to variable, dvs. hvordan bevÃ¦ger den ene variabel sig, nÃ¥r den anden bevÃ¦ger sig.

::::: two-column-layout
::: left-column
![](images/korrelationer.png)
:::

::: right-column
-   Positiv korrelation: NÃ¥r den ene variabel stiger, stiger den anden ogsÃ¥.

    <br>

-   Negativ korrelation: NÃ¥r den ene variabel stiger, falder den anden.

    <br>

-   Ikke lineÃ¦r sammenhÃ¦ng.
:::
:::::

------------------------------------------------------------------------

## Korrelationskoefficienter

Konkret arbejder man med korrelationskoefficienter, som er et mÃ¥l for korrelation:

-   Standardiseret mÃ¥l for styrken af en sammenhÃ¦ng.
-   Beskriver den lineÃ¦re sammenhÃ¦ng imellem dem.
-   Den ligger altid mellem $+1$ og $-1$ â€“ dog ikke for nominal skala.
-   SammenhÃ¦ngen er stÃ¦rkere, jo hÃ¸jere numerisk vÃ¦rdi den har.
-   NÃ¥r den er 0, er der ingen sammenhÃ¦ng.
-   $+/- 0.15$ betragtes som grÃ¦nsen for fortolkning.

------------------------------------------------------------------------

## Fra bi- til multivariat analyse

-   Korrelationskoefficienter fortÃ¦ller os, ***om*** to variable samvarierer, ***styrken*** af sammenhÃ¦ngen og ***retningen*** af sammenhÃ¦ngen (positiv / negativ)

-   **BegrÃ¦nsning**: bivariate korrelationsstudier kan ikke tage hÃ¸jde for mere end to variable

-   **Konsekvenser**: potentiel over-/undervurdering af sammenhÃ¦ngens styrke

------------------------------------------------------------------------

## Fra bi- til multivariat analyse

Multivariat analyse spÃ¸rger til:

-   ***Er der faktisk er en sammenhÃ¦ng*** mellem to variable, nÃ¥r vi tager hÃ¸jde for andre faktorer, som kan spille ind i korrelationen mellem dem?

-   ***Hvor stÃ¦rk*** er den isolerede (kausale) sammenhÃ¦ng mellem de to variable

-   ***Hvilke*** andre faktorer spiller en rolle

Endelig definerer vi variablenes indbyrdes forhold, dvs. **hvilken variabel pÃ¥virker den anden**

------------------------------------------------------------------------

## Variable i lineÃ¦r regression

-   I lineÃ¦r regressionsanalyse er vi som udgangspunkt stadig interesserede i at undersÃ¸ge sammenhÃ¦ngen mellem to variable, f.eks. uddannelse og indkomst

-   Disse to variable hedder henholdsvis den **afhÃ¦ngige** og **uafhÃ¦ngige** variabel

-   Den afhÃ¦ngige variabel er den, som pÃ¥virkes (â€afhÃ¦ngerâ€) af den uafhÃ¦ngige:

::: center
![](images/korrelationer.png)
:::

------------------------------------------------------------------------

## Variable i lineÃ¦r regression

-   Vi har altsÃ¥ en hypotese om, at ***der er en sammenhÃ¦ng*** mellem uddannelse og indkomst

-   Og vi har en teoretisk funderet hypotese om ***retningen*** pÃ¥ denne sammenhÃ¦ng: des flere Ã¥rs uddannelse du har, desto mere tjener du

::: center
![](images/reg3.png){width="743"}
:::

------------------------------------------------------------------------

## Hvorfor lineÃ¦r regression?

-   Vi har altsÃ¥ en hypotese om, at ***der er en sammenhÃ¦ng*** mellem uddannelse og indkomst

-   Og vi har en teoretisk funderet hypotese om ***retningen*** pÃ¥ denne sammenhÃ¦ng: des flere Ã¥rs uddannelse du har, desto mere tjener du

::: center
![](images/reg2.png){width="743"}
:::

Men hvad hvis en del af indkomstforskelle mellem hÃ¸jt/lavere uddannede skyldes, at dem der har lange uddannelser er Ã¦ldre og dermed har mere erfaring og anciennitet pÃ¥ arbejdsmarkedet?

------------------------------------------------------------------------

## Hvorfor lineÃ¦r regression?

-   Hvis alder korrelerer med bÃ¥de antal Ã¥rs uddannelse og indkomst, er alder en **confounding variable**

-   Det betyder, at en del af forskellen i indkomst mellem folk hÃ¸j/lavere uddannelse skyldes forskelle i alder - ikke uddannelse!

::: center
![](images/reg2.png){width="743"}
:::

------------------------------------------------------------------------

## Hvorfor lineÃ¦r regression?

Hvis vi ikke tager hÃ¸jde for, at noget af forskellen skyldes forskelle i alder, vil vi komme til at overvurdere (eller i andre tilfÃ¦lde undervurdere) sammenhÃ¦ngen mellem uddannelse og indkomst.

::: center
![](images/reg2.png){width="743"}
:::

------------------------------------------------------------------------

## Hvorfor lineÃ¦r regression?

-   Vores spÃ¸rgsmÃ¥l er i udgangspunktet, om uddannelse betyder noget for vores indkomstniveau
-   Men med lineÃ¦r regression kan vi ogsÃ¥ spÃ¸rge: hvor stÃ¦rk er sammenhÃ¦ngen mellem uddannelse og indkomst, nÃ¥r vi samtidig tager hÃ¸jde for forskelle i alder?
-   Her inddrager vi en tredje variabel, en ***kontrolvariabel***, der kontrollerer for denne tredje faktor

::: center
![](images/reg4.png){width="743"}
:::

------------------------------------------------------------------------

## Hvorfor lineÃ¦r regression?

-   At inddrage en kontrolvariabel svarer til kun at sammenligne observationer, der har samme vÃ¦rdi pÃ¥ kontrolvariablen
-   Dvs. man f.eks. estimerer sammenhÃ¦ngen mellem uddannelse og indkomst, mens man kun sammenligner observationer, der har samme alder.
-   Hvis der stadig er en sammenhÃ¦ng mellem den afhÃ¦ngige og uafhÃ¦ngige variabel, kan det altsÃ¥ ikke skyldes forskelle i kontrolvariablen (for den holdes konstant)

::: center
![](images/reg4.png){width="743"}
:::

------------------------------------------------------------------------

## Hvorfor lineÃ¦r regression?

-   Man kan altsÃ¥ estimere, hvor meget ens indkomst stiger, nÃ¥r ens uddannelse stiger, "renset" for pÃ¥virkningen af alder
-   Samtidig estimeres, hvor meget indkomst forventes at stige, nÃ¥r alder stiger, "renset" for pÃ¥virkningen af uddannelse

::: center
![](images/reg4.png){width="743"}
:::

------------------------------------------------------------------------

## Variable i lineÃ¦r regression

-   Man kan inkludere mange kontrolvariable i vores regressionsanalyse pÃ¥ en gang
-   Dermed kan man undersÃ¸ge, om sammenhÃ¦ngen mellem den afhÃ¦ngige og uafhÃ¦ngige variabel bestÃ¥r, selv nÃ¥r vi har kontrolleret for andre faktorer, som kunne tÃ¦nkes at forklare den sammenhÃ¦ngen

::: center
![](images/reg5.png){width="743"}
:::

------------------------------------------------------------------------

## Diskussion

<br>

**5 min**: diskutÃ©r hvilke andre kontrolvariable, der kunne vÃ¦re relevante i eksemplet med uddannelse og indkomst. Hvad karakteriserer en relevant kontrolvariabel?

---

## Hvordan

GrundlÃ¦ggende estimerer regressionsanalysen pÃ¥ korrelationen mellem variable

```{r echo=F, eval=T, message=F, warning=FALSE}
library(tidyverse)

ESS <- readRDS("Data/ESS.rds")
df <- ESS %>% filter(land=="DK") %>% 
  select(net_indkomst, udd_aar, alder, fagforeningsmedlem) %>% 
  na.omit()
```

::: panel-tabset
### Korrelationsplot

```{r echo=F, fig.width=6, fig.height=3}
library(ggplot2)

ggplot(df) +
  aes(x = udd_aar, y = net_indkomst) +
  geom_point() +
  labs(
    x = "Ã…rs uddannelse",
    y = "Indkomst (netto)"
  ) + ylim(0, 50000) +
  theme_minimal()

```

### Kode

```{r echo=T, eval=F}
ggplot(df) +
  aes(x = udd_aar, y = net_indkomst) +
  geom_point() +
  labs(
    x = "Ã…rs uddannelse",
    y = "Indkomst (netto)"
  ) + ylim(0, 50000) +
  theme_minimal()
```
:::

------------------------------------------------------------------------

## Hvordan

Der "fittes" sÃ¥ en linje, der minimerer den samlede afstand til alle punkter (mere om det senere). HÃ¦ldningen pÃ¥ denne linje, er udtryk for sammenhÃ¦ngens styrke.

::: panel-tabset
### Fittet linje

```{r echo=F, fig.width=6, fig.height=3}
library(ggplot2)

ggplot(df) +
  aes(x = udd_aar, y = net_indkomst) +
  geom_point() +
  labs(
    x = "Ã…rs uddannelse",
    y = "Indkomst (netto)"
  ) + ylim(0, 50000) +
  theme_minimal() +
  geom_smooth(method = "lm", color = "blue", se = FALSE)
```

### Kode

```{r echo=T, eval=F}
ggplot(df) +
  aes(x = udd_aar, y = net_indkomst) +
  geom_point() +
  labs(
    x = "Ã…rs uddannelse",
    y = "Indkomst (netto)"
  ) + ylim(0, 50000) +
  theme_minimal() +
  geom_smooth(method = "lm", color = "blue", se = FALSE)
```
:::

------------------------------------------------------------------------

## Hvordan

LineÃ¦r regression er en parametrisk metode, hvor man **antager**, at dataene kan beskrives med en bestemt formel, og hvor vi estimerer nogle faste **parametre** ud fra data.

-   I lineÃ¦r regression antager vi, at der er en **lineÃ¦r sammenhÃ¦ng** mellem vores variable

-   Disse sammenhÃ¦nge estimeres i form af parametre i en regressionsmodel

------------------------------------------------------------------------

## Eksempel

<br>

Lad os prÃ¸ve at tage gennemgÃ¥, hvordan en lineÃ¦r regressionsmodel skrives op og fortolkes med eksemplet fra Karlson (2017) teksten om lineÃ¦r regression i Survey bogen...

------------------------------------------------------------------------

## Simpel lineÃ¦r regression

Simpel lineÃ¦r regression betragter vi kun sammenhÃ¦ngen mellem en afhÃ¦ngig variabel $Y$ og en uafhÃ¦ngig variabel $X$

\
$Y=\alpha + \beta*X+\epsilon$

<br>

Denne model er simpel, fordi der kun er Ã©n variabel pÃ¥ hÃ¸jde side af lighedstegnet. I eksemplet med indkomst og uddannelse skrives det sÃ¥ledes:

<br>

$Indkomst = \alpha+\beta*uddannelse+\epsilon$

------------------------------------------------------------------------

## Simpel lineÃ¦r regression

Modellen har to parametre, $\alpha$ (alpha) og $\beta$ (beta)\
<br>

$Indkomst = \alpha+\beta*uddannelse+\epsilon$

<br>

-   $\alpha$ kaldes konstantleddet og fortolkes som den gennemsnitlige vÃ¦rdi af $Y$ (indkomst) nÃ¥r $X$ (uddannelse) er lig med 0.

-   Hvis man kan have mellem 0 og 20 Ã¥rs uddannelse, vil ğ›¼ reprÃ¦sentere den gennemsnitlige indkomst for dem, der har 0 Ã¥rs uddannelse.

------------------------------------------------------------------------

## Simpel lineÃ¦r regression

Modellen har to parametre, $\alpha$ (alpha) og $\beta$ (beta)\
<br>

$Indkomst = \alpha+\beta*uddannelse+\epsilon$

<br>

-   $\beta$ kaldes hÃ¦ldningskoefficienten og fortolkes som den gennemsnitlige Ã¦ndring i Y (indkomst), for Ã©n enhedsÃ¦ndring i (X) uddannelse.

-   $\beta$ reprÃ¦senterer i dette eksempel den forventede/gennemsnitlige Ã¦ndring i indkomst, nÃ¥r man fÃ¥r Ã©t Ã¥rs uddannelse mere.

-   $\beta$ er altsÃ¥ et estimat for sammenhÃ¦ngen mellem den afhÃ¦ngige variabel $Y$ og den uafhÃ¦ngige variabel $uddannelse$ som $\beta$ tilhÃ¸rer

------------------------------------------------------------------------

## Simpel lineÃ¦r regression

Det sidste tegn $\epsilon$ (epsilon) er fejlleddet eller residualet:

<br>

$Indkomst = \alpha+\beta*uddannelse+\epsilon$

<br>

-   Fejlleddet er en variabel (ikke et parameter), som indeholder hver respondents afvigelse mellem respondenternes observerede indkomst og den indkomst, som regressionsmodellen forudsiger, at respondenten har, pÃ¥ baggrund af ğ›¼ og ğ›½.

-   $\epsilon$ opsummerer med andre ord den variation i Y (indkomst), som ikke kan forklares af X (uddannelse).

------------------------------------------------------------------------

## Simpel lineÃ¦r regression

::::: two-column-layout
::: left-column
![](images/reg6.png)
:::

::: right-column
-   Parametre og fejlled kan fremstilles grafisk

-   Pointen med lineÃ¦r regression er at lÃ¦gge en lige linje gennem alle respondenters koordinater

-   Linjen estimeres sÃ¥ledes, at der er mindst mulig afstand til hver af datapunkterne

-   Denne afstand opfanges af $\epsilon$
:::
:::::

------------------------------------------------------------------------

## Simpel lineÃ¦r regression

::::: two-column-layout
::: left-column
![](images/reg6.png)
:::

::: right-column
-   $\beta$ er hÃ¦ldningen pÃ¥ linjen, netop derfor kaldes den for *hÃ¦ldningskoefficienten*

-   $\beta$ reprÃ¦senterer stigningen pÃ¥ Y-aksen, nÃ¥r ğ‘‹ stiger med 1

-   Stigningen aflÃ¦ses altsÃ¥ pÃ¥ y-aksen
:::
:::::

------------------------------------------------------------------------

## Multipel lineÃ¦r regression

I den simple lineÃ¦re regression er $\beta$-koefficienten udtryk for en ubetinget eller â€ikke-kontrolleretâ€ lineÃ¦r sammenhÃ¦ng mellem $X$ og $Y$

<br>

$Indkomst = \alpha+\beta*uddannelse+\epsilon$

<br>

I multipel lineÃ¦r regression introducerer vi en tredje variabel (kontrolvariabel) $Z$, som placeres pÃ¥ hÃ¸jre side af lighedstegnet:

$Indkomst = \alpha+\beta*uddannelse+\delta Z+\epsilon$

------------------------------------------------------------------------

## Multipel lineÃ¦r regression

$Indkomst = \alpha+\beta*uddannelse+\delta*Z+\epsilon$

<br>

-   Konstantleddet $\alpha$ fortolkes nu som den gennemsnitlige vÃ¦rdi af $Y$ nÃ¥r bÃ¥de $X$ og $Z$ er lig med 0 <br>
-   Fejlledet $\epsilon$ fortolkes som den del af variationen i $Y$ som ikke kan forklares af bÃ¥de $ğ‘‹$ og $ğ‘$

------------------------------------------------------------------------

## Multipel lineÃ¦r regression

-   I simpel lineÃ¦r regression er $\beta$ en â€ubetingetâ€ lineÃ¦r sammenhÃ¦ng mellem $ğ‘‹$ og $Y$:

$Y = \alpha+\beta*X+\epsilon$

-   Men i den multiple regressionsmodel er $\beta$ den â€betingede/partielleâ€ sammenhÃ¦ng mellem $ğ‘‹$ og $Y$ nÃ¥r vi kontrollerer for $ğ‘$

$Y = \alpha+\beta*X+\delta*Z+\epsilon$

-   At â€kontrollere for $ğ‘$â€ betyder, at vi kun sammenligner folk, men samme vÃ¦rdi pÃ¥ variablen $ğ‘$.

-   Her er $\beta$ altsÃ¥ den forventede Ã¦ndring i $Y$ for en enhedsÃ¦ndring i $ğ‘‹$, nÃ¥r man sammenligner folk, men samme vÃ¦rdi pÃ¥ $ğ‘$

------------------------------------------------------------------------

## Multipel lineÃ¦r regression

Delta ğ›¿ fortolkes ligesom $\beta$

$Y = \alpha+\beta*X+\delta*Z+\epsilon$

<br>

-   Koefficienten $\delta$ er bare den â€betingede/partielleâ€ sammenhÃ¦ng mellem $Z$ og $Y$ nÃ¥r vi kontrollerer for $X$

-   At â€kontrollere for $X$â€ betyder, at vi kun sammenligner folk, men samme vÃ¦rdi pÃ¥ variablen $X$.

-   Her er $\delta$ altsÃ¥ den forventede Ã¦ndring i $Y$ for en enhedsÃ¦ndring i $Z$, nÃ¥r man sammenligner folk, men samme vÃ¦rdi pÃ¥ $X$

------------------------------------------------------------------------

## Multipel lineÃ¦r regression

Lad os sige, at:

-   $Y$ mÃ¥ler indkomst i DKK

-   $X$ mÃ¥ler uddannelse i Ã¥r

-   $Z$ mÃ¥ler alder

$Indkomst = \alpha+\beta*uddannelse+\delta*alder+\epsilon$

------------------------------------------------------------------------

## Multipel lineÃ¦r regression

$Indkomst = \alpha+\beta*uddannelse+\delta*alder+\epsilon$

<br>

SÃ¥ vil:

-   $\alpha$ vÃ¦re den gennemsnitlige indkomst for en person med 0 Ã¥rs uddannelse og en alder pÃ¥ 0 Ã¥r

-   $\beta$ vÃ¦re den forventede Ã¦ndring i indkomst, hver gang uddannelse stiger med 1 (Ã¥r), nÃ¥r vi sÃ¸rger for kun at sammenligne folk der er lige gamle, og dermed tager hÃ¸jde for effekten af alder

-   $\delta$ vÃ¦re den forventede Ã¦ndring i indkomst, hver gang alder stiger med 1 (Ã¥r), nÃ¥r vi kontrollerer for uddannelse

-   $\epsilon$ vÃ¦re den del af variationen i ğ‘Œ som ikke kan forklares af bÃ¥de $X$ og $X$

------------------------------------------------------------------------

## Multipel lineÃ¦r regression

I dette eksempel vil variablene have fÃ¸lgende roller:

![](images/reg7.png){fig-align="center" width="515"}

-   Variable er dem vi specificerer i vores regression i R

-   Koefficienterne er de tal, som vi aflÃ¦ser som resultater

------------------------------------------------------------------------

## Multipel lineÃ¦r regression

-   Pointen med at indfÃ¸re kontrolvariable er, at vi kan fÃ¥ den â€reneâ€ sammenhÃ¦ng mellem to variable (f.eks. Uddannelse og indkomst), renset for effekten af confounding variables (sÃ¥som alder)

![](images/reg8.png){fig-align="center"}

------------------------------------------------------------------------

## Hypotesetest i lineÃ¦r regression

NÃ¥r vi tester, om der er en sammenhÃ¦ng mellem ğ‘‹ og ğ‘Œ i lineÃ¦r regression, laver vi faktisk bare en t-test pÃ¥ den tilhÃ¸rende koefficient ğ›½:

<br>

**H0**: ğ›½ (hÃ¦ldningen) er lig med 0

**H1**: ğ›½ (hÃ¦ldningen) er ikke lig med nul

<br>

-   Vi bruger som altid p-vÃ¦rdien til at afgÃ¸re, om vi kan forkaste nulhypotesen! Hvis p-vÃ¦rdien er under 0,05 siger vi, at der er en statistisk signifikant sammenhÃ¦ng mellem ğ‘‹ og ğ‘Œ (selv nÃ¥r vi kontrollerer for ğ‘).

-   Vi laver i princippet prÃ¦cis samme test for ğ›¿, for at teste, om der er en statistisk signifikant sammenhÃ¦ng mellem ğ‘ og ğ‘Œ (selv nÃ¥r vi kontrollerer for ğ‘‹).

------------------------------------------------------------------------

## LineÃ¦r regression i R

I skal bruge funktionen `lm()` til at estimere regressionsmodeller. Syntaksen er som fÃ¸lgende med *k* antal kontrolvariable:

```{r echo=TRUE, eval=F, message=F, warning=FALSE}
model <- lm(afhÃ¦ngig_variabel ~ uafhÃ¦ngig_variabel +
            kontrol_variabel_1 + kontrol_variabel_2 ...
            kontrol_variabel_k, 
            data=df)
```

Resultatet af regressionsanalysen gemmes i objektet *model*. Brug `texreg::screenreg()` til at printe resultaterne i consollen:

```{r echo=TRUE, eval=F, message=F, warning=FALSE}
(texreg::screenreg(list(model), include.ci = F))
```

------------------------------------------------------------------------

## LineÃ¦r regression i R

Eks. $Indkomst = \alpha+\beta*uddannelse+\epsilon$

::: panel-tabset
### output

```{r echo=F, fig.width=6, fig.height=3}
model1 <- lm(net_indkomst ~ udd_aar, data = df)

library(texreg)
(texreg::screenreg(list(model1), include.ci=F))
```

### Kode

```{r echo=T, eval=F}
model1 <- lm(net_indkomst ~ udd_aar, data = df)

library(texreg)
(texreg::screenreg(list(model1), include.ci=F))
```
:::

***Intercept***: parameterestimatet for konstantleddet $\alpha=10754,2$ . Dette er den forventede vÃ¦rdi pÃ¥ den afhÃ¦ngige variabel indkomst, nÃ¥r vÃ¦rdien pÃ¥ den uafhÃ¦ngige variabel *antal Ã¥rs uddannelse* = 0. AltsÃ¥ den forventede indkomst for en person med 0 Ã¥rs udddannelse.

------------------------------------------------------------------------

## LineÃ¦r regression i R

Eks. $Indkomst = \alpha+\beta * uddannelse+\epsilon$

::: panel-tabset
### output

```{r echo=F, fig.width=6, fig.height=3}
model1 <- lm(net_indkomst ~ udd_aar, data = df)

library(texreg)
(texreg::screenreg(list(model1), include.ci=F))
```

### Kode

```{r echo=T, eval=F}
model1 <- lm(net_indkomst ~ udd_aar, data = df)

library(texreg)
(texreg::screenreg(list(model1), include.ci=F))
```
:::

***udd_aar***: parameterstimatet for $\beta=380,33$. Dette er den forventede stigning i den afhÃ¦ngige variabel (indkomst*)* for hver gang den uafhÃ¦ngige variabel (antal Ã¥rs uddannelse)stiger med 1. AltsÃ¥ den forventede stigning i indkomst hver gang en person har 1 Ã¥rs uddannelse mere.

------------------------------------------------------------------------

## LineÃ¦r regression i R

`texreg` printer stjerner som indikatorer for, om parameterestimater er signifikante. Forklaringen i bunden af tabellen viser, at:

<br>

**\*\*\*** betyder, at p-vÃ¦rdien for parameterestimatet er mindre end 0,001

**\*\*** betyder, at p-vÃ¦rdien for parameterestimatet er mindre end 0,01

**\*** betyder, at p-vÃ¦rdien for parameterestimatet er mindre end 0,05

<br>

Det fremgÃ¥r altsÃ¥ af tabellen, at der er en signifikant sammenhÃ¦ng mellem den afhÃ¦ngige variabel, *indkomst*, og uafhÃ¦ngige variabel *antal Ã¥rs uddannelse* $(p < 0,001)$.

------------------------------------------------------------------------

## LineÃ¦r regression i R

Eks. $Indkomst = \alpha+\beta*uddannelse+\delta*alder+\epsilon$

::: panel-tabset
### output

```{r echo=F, fig.width=6, fig.height=3}
model2 <- lm(net_indkomst ~ udd_aar + alder, data = df)

(texreg::screenreg(list(model1, model2), include.ci=F))
```

### Kode

```{r echo=T, eval=F}
model2 <- lm(net_indkomst ~ udd_aar + alder, data = df)

(texreg::screenreg(list(model1, model2), include.ci=F))
```
:::

Vi kan nu se parameterestimater fra bÃ¥de model 1 og model 2

------------------------------------------------------------------------

## LineÃ¦r regression i R

Eks. $Indkomst = \alpha+\beta*uddannelse+\delta*alder+\epsilon$

::: panel-tabset
### output

```{r echo=F, fig.width=6, fig.height=3}
model2 <- lm(net_indkomst ~ udd_aar + alder, data = df) 

(texreg::screenreg(list(model1, model2), include.ci=F))
```

### Kode

```{r echo=T, eval=F}
model2 <- lm(net_indkomst ~ udd_aar + alder, data = df)

(texreg::screenreg(list(model1, model2), include.ci=F))
```
:::

***Intercept***: parameterestimatet for konstantleddet har nu Ã¦ndret sig til $\alpha=9767$ . Dette er den forventede vÃ¦rdi pÃ¥ den afhÃ¦ngige variabel indkomst, nÃ¥r vÃ¦rdien pÃ¥ den uafhÃ¦ngige variabel *antal Ã¥rs uddannelse* = 0 og kontrolvariablen *alder = 0*. AltsÃ¥ den forventede indkomst for en person med 0 Ã¥rs udddannelse pÃ¥ 0 Ã¥r.

------------------------------------------------------------------------

## LineÃ¦r regression i R

Eks. $Indkomst = \alpha+\beta*uddannelse+\delta*alder+\epsilon$

::: panel-tabset
### output

```{r echo=F, fig.width=6, fig.height=3}
model2 <- lm(net_indkomst ~ udd_aar + alder, data = df)

(texreg::screenreg(list(model1, model2), include.ci=F))
```

### Kode

```{r echo=T, eval=F}
model2 <- lm(net_indkomst ~ udd_aar + alder, data = df)

(texreg::screenreg(list(model1, model2), include.ci=F))
```
:::

***udd_aar***: parameterstimatet for $\beta=387,68$. Dette er stadig den forventede stigning i den afhÃ¦ngige variabel (indkomst*)* for hver gang den uafhÃ¦ngige variabel (antal Ã¥rs uddannelse) stiger med 1. Men nu er det den estimerede stigning, nÃ¥r vi HAR taget hÃ¸jde for alder.

------------------------------------------------------------------------

## LineÃ¦r regression i R

Eks. $Indkomst = \alpha+\beta*uddannelse+\delta*alder+\epsilon$

::: panel-tabset
### output

```{r echo=F, fig.width=6, fig.height=3}
model2 <- lm(net_indkomst ~ udd_aar + alder, data = df)

(texreg::screenreg(list(model1, model2), include.ci=F))
```

### Kode

```{r echo=T, eval=F}
model2 <- lm(net_indkomst ~ udd_aar + alder, data = df)

(texreg::screenreg(list(model1, model2), include.ci=F))
```
:::

***alder***: parameterstimatet for $\delta=17,76$. Dette er - ligesom estimatet for $\beta$ - den forventede stigning i den afhÃ¦ngige variabel (indkomst*)* for hver gang den kontrolvariablen (alder) stiger med 1. Det er tilmed den estimerede stigning, nÃ¥r vi HAR taget hÃ¸jde for *uddannelse*. Ingen stjerner betyder, at estimatet er insignifikant.

------------------------------------------------------------------------

## Hvad kigger vi efter?

Vi har nu testet bÃ¥de den rÃ¥ og den kontrollerede sammenhÃ¦ng mellem indkomst og uddannelse. Det vi kigger efter er:

-   Var der en statistisk signifikant sammenhÃ¦ng mellem uddannelse og indkomst (aflÃ¦ses i $\beta$ **fÃ¸r** vi inkluderede kontrolvariablen?

-   Ã†ndrede sammenhÃ¦ngen ( stÃ¸rrelsen pÃ¥ $\beta$) sig, **efter** vi inkluderede kontrolvariablen?

-   Blev samenhÃ¦ngen ($\beta$) insignifikant, da vi inkluderede kontrolvariablen.

-   Skal kontrolvariablen indgÃ¥ i modellen, eller er den insignifikant (irrelevant)?

FremgangsmÃ¥den kaldes *forlÃ¦ns modelsÃ¸gning*, hvilket vi skal lave i nÃ¦ste uge.

------------------------------------------------------------------------

## Forventede vÃ¦rdier

NÃ¥r modellens parametre er estimeret, kan man anvende modellens formel til at udregne ***forventede vÃ¦rdier*** pÃ¥ den afhÃ¦ngige variabel, for forskellige niveauer pÃ¥ de uafhÃ¦ngige variable:

1\) $Indkomst = \alpha+\beta*uddannelse+\epsilon$

2\) $Indkomst = 9767 +387*uddannelse+\epsilon$

<br>

Dermed kan man f.eks. udregne den forventede indkomst for en person med 15 Ã¥rs uddannelse:

3\) $Indkomst = 9767 +387*15= \underline{\underline{15.572}}$

------------------------------------------------------------------------

## Forventede vÃ¦rdier

5 min: prÃ¸v med udgangspunkt i nedenstÃ¥ende at udregne den forventede indkomst for en person med 18 Ã¥rs uddannelse:

$Indkomst = \alpha+\beta * uddannelse+\epsilon$

::: panel-tabset
### output

```{r echo=F, fig.width=6, fig.height=3}
model1 <- lm(net_indkomst ~ udd_aar, data = df)  

(texreg::screenreg(list(model1), include.ci=F))
```

### Kode

```{r echo=T, eval=F}
model1 <- lm(net_indkomst ~ udd_aar, data = df)  

(texreg::screenreg(list(model1), include.ci=F))
```
:::

---

## LineÃ¦r regressionsanalyse kan anvendes...

<br>

-   **Deskriptivt/beskrivende** til at beskrive sammenhÃ¦nge mellem flere variable

-   **Forklarende** ved at teste, om sammenhÃ¦nge mellem to variable bestÃ¥r, nÃ¥r der kontrolleres for andre faktorer samtidig

-   **Forudsigende** pÃ¥ baggrund af data og model (f.eks. hvor meget kan jeg forvente at tjene, givet mit uddannelsesniveau og alder)

------------------------------------------------------------------------

## Hvorfor lineÃ¦r regression?

Der findes andre typer af regressionsanalyse, sÃ¥ hvorfor skal vi lÃ¦re lineÃ¦r?

-   Det er den mest anvendte

-   Metoden er sindssygt robust og kan anvendes til mange forskellige spÃ¸rgsmÃ¥l

-   Det er et godt udgangspunkt for at lÃ¦re mere avanceret statistik.

---

## Ã˜velse

GÃ¥ ind i kodebogen og installÃ©r den nÃ¸dvendige pakke `texreg` (se under afsnittet *Multivariat analyse*).

<br>

Download datasÃ¦ttet `ESS` fra lectio og prÃ¸v at genskabe regressionsmodellerne fra de to modeller:

Model 1: $Indkomst = \alpha+\beta*uddannelse+\epsilon$

Model 2: $Indkomst = \alpha+\beta*uddannelse+\delta*alder+\epsilon$
