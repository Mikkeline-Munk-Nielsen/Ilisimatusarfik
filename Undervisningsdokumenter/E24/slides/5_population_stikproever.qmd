---
format: 
  revealjs:
    theme: css_etc/custom-theme-ilisimatusarfik.css
    slide-level: 0  # Disable automatic slide creation from headings
    incremental: false 
    logo: css_etc/ilisimatusarfik.png
editor: visual
---

::: center
# Populationer og stikprÃ¸ver

### Statistik E24 (15 ECTS)

### ved Mikkeline Munk Nielsen
:::

------------------------------------------------------------------------

# Program

-   Hvad er populationer og stikprÃ¸ver?
-   Hvordan udtrÃ¦kker man stikprÃ¸ver?
-   Hvorfor stikprÃ¸ver introducerer statistisk usikkerhed
-   Hvordan regner vi pÃ¥ statistisk usikkerhed?

------------------------------------------------------------------------

# Populationer

I statistik betegnes en population som den mÃ¦ngde af enheder, som vi gerne vil udtale os om. Hvis vi gerne vil udtale os om aldersfordelingen blandt borgere i GrÃ¸nland er populationen altsÃ¥ samtlige borgere i GrÃ¸nland. Man skelner dog mellem:

<br>

-   **Universet/populationen (target population):** den mÃ¥lgruppe, hvori en stikprÃ¸ve trÃ¦kkes

-   **Den mulige population (frame population):** den del af universet, som faktisk *kan* udtrÃ¦kkes og dermed har mulighed for at indgÃ¥ i stikprÃ¸ven

------------------------------------------------------------------------

# Populationer

-   Hvis vi har information pÃ¥ ALLE de enheder, som vi gerne vil udtale os om har vi mulighed for at lave populationsundersÃ¸gelser/totalundersÃ¸gelser

-   RegisterundersÃ¸gelser er det, der kommer tÃ¦ttest pÃ¥: <https://stat.gl/default.asp?lang=da>

-   Oftest har vi dog hverken tid eller rÃ¥d til at gennemfÃ¸re populationsundersÃ¸gelser...

------------------------------------------------------------------------

# StikprÃ¸ver

En stikprÃ¸ve er en lille del af universet, der udvÃ¦lges til at reprÃ¦sentere/beskrive hele universet ![](images/udtraek.png)

------------------------------------------------------------------------

# UdtrÃ¦k af stikprÃ¸ver

Selvom mange observationer umiddelbart er godt, sÃ¥ er mÃ¥den, hvorpÃ¥ en stikprÃ¸ve udtrÃ¦kkes faktisk meget vigtigere for reprÃ¦sentativiteten end stÃ¸rrelsen pÃ¥ stikprÃ¸ven. I skal kende fÃ¸lgende tre strategier:

<br>

-   Simpel tilfÃ¦ldig (Gold standard)

-   Stratificeret: reduceret variation inden for strata

-   Klynge: UdtrÃ¦k af klynger (ikke enkelte enheder)

------------------------------------------------------------------------

# Simpel tilfÃ¦ldigt udtrÃ¦k

::::: two-column-layout
::: left-column
-   Hver observation i populationen har lige sandsynlighed for at blive udtrukket
-   Anses som "gold standard" for stikprÃ¸veudtagning
-   Bruges til at minimere bias og sikre, at stikprÃ¸ven reprÃ¦senterer hele populationen
:::

::: right-column
![](images/numbers_from_hat.jpg)
:::
:::::

------------------------------------------------------------------------

# Stratificeret udtrÃ¦k

::::: two-column-layout
::: left-column
-   Populationen opdeles i strata (grupper) baseret pÃ¥ en relevant variabel (fx kommune, kÃ¸n)
-   TilfÃ¦ldig udtrÃ¦kning sker inden for hver stratum
-   Reduceret variation inden for hvert stratum (enheder er ens inden for strata, i princippet)
-   FormÃ¥let er at sikre, at alle vigtige undergrupper er reprÃ¦senterede
:::

::: right-column
![](images/kommuner.png){width="75%"}
:::
:::::

------------------------------------------------------------------------

# KlyngeudtrÃ¦k

::::: two-column-layout
::: left-column
-   Populationen opdeles i klynger (fx skoler, husstande), og udtrÃ¦kning sker pÃ¥ klyngeniveau (ikke inden for klynger, ligesom med stata)

-   UdvÃ¦lger hele klynger fremfor enkeltindivider inden for populationen

-   Effektiv, nÃ¥r det er praktisk at udtrÃ¦kke data fra grupper fremfor hele populationen

-   Velegnet til store geografiske eller administrative enheder, hvor stikprÃ¸ver er svÃ¦re at indsamle
:::

::: right-column
![](images/huse.jpg)
:::
:::::

------------------------------------------------------------------------

# StikprÃ¸veudtrÃ¦k og statistisk usikkerhed

-   PÃ¥ baggrund af en stikprÃ¸ve drages konklusioner om en population (inferens). Slutningen er baseret pÃ¥ stikprÃ¸vens **reprÃ¦sentativitet**

-   Den bedste mÃ¥de at opnÃ¥ reprÃ¦sentativitet pÃ¥ er at anvende en udvÃ¦lgelsesmekanisme baseret pÃ¥ **tilfÃ¦ldighed!**

**Hvorfor virker tilfÃ¦ldigt udtrÃ¦k ift. at sikre en reprÃ¦sentativ stikprÃ¸ve?**

-   Hver enhed i populationen har samme sandsynlighed for at blive udvalgt (undgÃ¥r systematisk bias/skÃ¦vvridning)
-   Sikrer, at stikprÃ¸ven i *gennemsnit* er reprÃ¦sentativ for populationen.
-   TilfÃ¦ldighed i stikprÃ¸veudtrÃ¦k bygger pÃ¥ principper om lige sandsynlighed, store tals lov og den centrale grÃ¦nsevÃ¦rdisÃ¦tning.

------------------------------------------------------------------------

# StikprÃ¸veudtrÃ¦k og statistisk usikkerhed

-   Fordi en stikprÃ¸ve ikke svarer prÃ¦cist den population, som den er trukket fra, vil der altid vÃ¦re en ***statistisk usikkerhed*** forbundet med en generalisering fra stikprÃ¸ve til population (ogsÃ¥ kaldt margin of error).

-   Statistik handler bl.a. om at sige noget under usikkerhed og om at vurdere, hvor stor usikkerheden pÃ¥ ens udsagn er.

------------------------------------------------------------------------

# StikprÃ¸veudtrÃ¦k og statistisk usikkerhed

-   Usikkerhed opstÃ¥r pga. ***udvÃ¦lgelsesmekanismen***, nÃ¥r vi trÃ¦kker en stikprÃ¸ve.

-   Hvis vi f.eks. har en hat med sedler med alle navne pÃ¥ folk i GrÃ¸nland (populationen), ryster hatten og lukker Ã¸jnene for at trÃ¦kke et navn, er der usikkerhed, hver gang vi trÃ¦kker, fordi vi ikke kender udfaldet. Hvis vi gentager dette 1000 gange, har vi en stikprÃ¸ve pÃ¥ 1000 personer.

-   Man kalder denne proces for et ***eksperiment*** inden for statistik.

-   For at hÃ¥ndtere usikkerhed opstiller man en matematisk sandsynlighedsmodel, som gÃ¸r os i stand til at regne pÃ¥ usikkerheden

------------------------------------------------------------------------

# StikprÃ¸veudtrÃ¦k og statistisk usikkerhed

Sandsynlighedsmodellen bygger pÃ¥ tre ting:

1)  **Udfaldsrum** $\Omega$: alle mulige udfald/vÃ¦rdier af eksperimentet. I terningekast er $\Omega = \{1, 2, 3, 4, 5, 6\}$

2)  **HÃ¦ndelser**: samlinger af udfald. En hÃ¦ndelse $A$ kunne f.eks. vÃ¦re at terningen viser et ulige antal Ã¸jne. SÃ¥ vil hÃ¦ndelse $A = \{1, 3, 5\}$

3)  **SandsynlighedsmÃ¥l**: hvis alle elementer i en population har lige stor chance for udvÃ¦lgelse, sÃ¥ er sandsynligheden for et udfald $z$ lig med vÃ¦rdien af andelsfunktionen evalueret i $z$:

    $$ P(z) = g(z) = \frac{\text{antal elementer med vÃ¦rdien } z \text{ i populationen}}{N_{\text{pop}}} $$

------------------------------------------------------------------------

# StikprÃ¸veudtrÃ¦k og statistisk usikkerhed

-   I â€eksperimenterâ€ kender vi ikke udfaldet/vÃ¦rdien pÃ¥ den variabel, som vi er ved at trÃ¦kke. En variabel som endnu ikke har haft et udfald, og som derfor har tilknyttet usikkerhed, kaldes en ***stokastisk variabel***.

-   En stokastisk variabel $X$ er en funktion, som til ethvert udfald af et eksperiment forbinder en talvÃ¦rdi fra udfaldsrummet: $ğ‘‹(ğ‘¢ğ‘‘ğ‘“ğ‘ğ‘™ğ‘‘)=ğ‘¡ğ‘ğ‘™ (\text{ğ‘“ğ‘Ÿğ‘ ğ‘¢ğ‘‘ğ‘“ğ‘ğ‘™ğ‘‘ğ‘ ğ‘Ÿğ‘¢ğ‘šğ‘šğ‘’ğ‘¡})$

-   Stokastiske variable reprÃ¦senterer udfald af et eksperiment.

------------------------------------------------------------------------

# StikprÃ¸veudtrÃ¦k og statistisk usikkerhed

Stokastiske variable kan vÃ¦re enten diskrete eller kontinuerte. Dette har betydning for, hvordan vi tilskriver sandsynlighed til deres vÃ¦rdier.

-   **Diskrete variable:** ting som man kan tÃ¦lle. F.eks. Antal Ã¸jne pÃ¥ en terning eller antal varer solgt i en butik

-   **Kontinuerte variable:** variabler med uendeligt mange udfald inden for en given range. F.eks. VandmÃ¦ngden i en vandflaske eller produktionstid for en vare. Begge tilfÃ¦lde kan have uendeligt mange decimaler.

------------------------------------------------------------------------

# StikprÃ¸veudtrÃ¦k og statistisk usikkerhed

Stokastiske variable har ogsÃ¥ fordelinger. Der er to sÃ¦rligt vigtige fordelinger, som I skal kende til:

-   **Binomial-fordelingen**: for diskrete stokastiske variable

-   **Normalfordelingen**: for kontinuerte stokastiske variable

------------------------------------------------------------------------

# Binomial-fordeling

-   Man bruger binomialfordelingen, nÃ¥r man gentager et forsÃ¸g, der kun har to udfald (Bernoulli-forsÃ¸g). I statistik kaldes disse som regel succes og fiasko. Succes kan bÃ¥de defineres som f.eks. at slÃ¥ â€kroneâ€ i plat og krone, men ogsÃ¥ bare som at observere en sÃ¦rlig vÃ¦rdi, f.eks. â€kvindeâ€ i en population.

-   Forestil dig, at du 1000 gange trÃ¦kker en tilfÃ¦ldig person fra den grÃ¸nlandske population, og Ã¸nsker at vide sandsynligheden for at trÃ¦kke en kvinde. Binomialfordelingen kan hjÃ¦lpe med at beregne dette.

![](images/platkrone.png){width="50%"}

------------------------------------------------------------------------

# Binomial-fordeling

-   Vi bruger binomialfordelingen, nÃ¥r vi arbejder med andele. Hvis alle enheder i populationen har lige stor chance for udvÃ¦lgelse, sÃ¥ er sandsynligheden for udfaldet $z$ nemlig lig andelen af enheder i populationen med vÃ¦rdi $z$:

$$
P(z) = \frac{\text{antal enheder i population med vÃ¦rdien } z \text{ i populationen}}{N_{\text{pop}}}
$$ - NÃ¥r vi skal udregne statistisk usikkerhed forbundet med andele af f.eks. kvinder i vores stikprÃ¸ve, gÃ¸r vi det altsÃ¥ pÃ¥ baggrund af sandsynligheden for at trÃ¦kke en kvinde, nÃ¥r vi trÃ¦kker vores stikprÃ¸ve fra populationen!

------------------------------------------------------------------------

# Binomial-fordeling

MiddelvÃ¦rdi og varians for binomialfordelte variable udregnes som fÃ¸lgende:

$$
\text{MiddelvÃ¦rdi: } E(Y) = n \cdot p \\
\text{Varians: } V(Y) = n \cdot p \cdot (1 - p)
$$

$Y$ angiver antal succeser blandt $n$ uafhÃ¦ngige udtrÃ¦kninger fra en population, hvor udfaldsrummet $\Omega=\text{{success, fiasko}}$ og der er konstant sandsynlighed, $ğ‘$, for succes i hver udtrÃ¦kning.

------------------------------------------------------------------------

# Binomial-fordeling

-   Vi ved, at *middelvÃ¦rdi* $E(Y) = n*p$ ogsÃ¥ kan fortolkes som *andelen* af observationerne i stikprÃ¸ven med den vÃ¦rdi, som vi har angivet som "success".

-   Hvis alle elementer i populationen har lige stor chance for udvÃ¦lgelse, sÃ¥ er sandsynligheden for udfaldet $z$ nemlig lig andelen af elementer i populationen med vÃ¦rdi $z$:

    $P(z) = \frac{\text{antal enheder i population med vÃ¦rdien } z \text{ i populationen}}{N_{\text{pop}}}$

-   Men vi ved ogsÃ¥, at et stikprÃ¸vegennemsnit er behÃ¦ftet med en hvis usikkerhed ift. populationsgennemsnittet, fordi udvÃ¦lgelsesmekanismen har introduceret en vis tilfÃ¦ldighed. Derfor vil vi gerne kunne sige noget om, hvor stor usikkerheden er!

------------------------------------------------------------------------

# Store Tals Lov

-   Store Tals Lov siger, at nÃ¥r stikprÃ¸vestÃ¸rrelsen ($n$ ) bliver stor, vil gennemsnittet i stikprÃ¸ven nÃ¦rme sig populationens sande gennemsnit, ($\mu$):\
    $$
    \frac{1}{n} \sum_{i=1}^{n} X_i \rightarrow \mu \quad \text{nÃ¥r } n \to \infty
    $$ hvor ( $X_i$ ) er en tilfÃ¦ldig variabel i stikprÃ¸ven, og ($\mu$) er populationsgennemsnittet.

-   **Implikation:** Store Tals Lov giver os en garanti for, at stikprÃ¸vegennemsnittet bliver tÃ¦ttere pÃ¥ populationsgennemsnittet, efterhÃ¥nden som stikprÃ¸ven bliver stÃ¸rre!

-   Vi kan altsÃ¥ mindre usikkerheden pÃ¥ vores resultater ved at Ã¸ge stikprÃ¸vestÃ¸rrelsen... men hvordan ved vi, hvor stor usikkerhed vores resultater faktisk er behÃ¦ftet med?

------------------------------------------------------------------------

# Den centrale grÃ¦nsevÃ¦rdisÃ¦tning

<br>

Den centrale grÃ¦nsevÃ¦rdisÃ¦tning fortÃ¦ller os, at uanset hvilken fordeling hver observation fra en simpel tilfÃ¦ldig stikprÃ¸ve fÃ¸lger, sÃ¥ er stikprÃ¸vegennemsnittet approksimativt (â€sÃ¥ godt somâ€) normalfordelt, nÃ¥r bare stikprÃ¸ven er tilstrÃ¦kkelig stor.

*(Malchow-MÃ¸ller & WÃ¼rst 2014:242)*

------------------------------------------------------------------------

# Normalfordeling

Hvad er sÃ¥ sÃ¦rligt ved normalfordelingen?

Mange naturlige stÃ¸rrelser i virkelige populationer har en fordeling, som ligner normalfordelingen, f.eks. hÃ¸jde i en befolkning. Mange estimatorer og test-statistikker er normalfordelte; f.eks. stikprÃ¸vegennemsnit jf. den centrale grÃ¦nsevÃ¦rdisÃ¦tning

```{r include=T, echo=F, message=F, warning=F}
library(ggplot2)

# Definer parametre for normalfordelingen
mean <- 0       # Gennemsnit
sd <- 1         # Standardafvigelse

# Opret et data frame med x-vÃ¦rdier og deres sandsynlighedstÃ¦thed
x <- seq(-4, 4, length.out = 100)  # Interval for x
y <- dnorm(x, mean, sd)            # Beregn sandsynlighedstÃ¦thed for normalfordelingen

# Kombiner x og y til et data frame
df <- data.frame(x, y)

# Plot normalfordelingen
(normalfordeling <- ggplot(df, aes(x = x, y = y)) +
  geom_line(color = "blue", size = 1) +
  labs(y = "SandsynlighedstÃ¦thed", x="Data") +
  theme_minimal() +
  theme(
    text = element_text(size = 16),            # General text size
    axis.title = element_text(size = 18),      # Axis title size
    axis.text = element_text(size = 14),       # Axis labels size
  ))
```

------------------------------------------------------------------------

# Normalfordeling

-   Normalfordelingen er kendetegnet ved at vÃ¦re symmetrisk fordelt omkring middelvÃ¦rdi $\mu$, og dens bredde afhÃ¦nger af varians $\sigma^2$.

-   Kurven (tÃ¦thedsfunktionen) angiver sandsynligheden for at observere en given vÃ¦rdi.

-   Hvis en stokastisk variabel $Y$ er normalfordelt $Y \sim \mathcal{N}(\mu, \sigma^2)$ sÃ¥ er det altsÃ¥ mest sandsynligt at observere vÃ¦rdier, der ligger tÃ¦t pÃ¥ gennemsnittet.

-   Vi kan bruge denne information til at regne pÃ¥ usikkerheden pÃ¥ vores resultater!

------------------------------------------------------------------------

# Normalfordeling

-   Faktisk er normalfordelte variable skruet sÃ¥dan sammen, at vi ud fra standardafvigelsen pÃ¥ en variabel kan sige, hvor stor en andel af observationerne der ligger inden for et given afstand til gennemsnittet.

-   Derfor kan man bruge standardafvigelsen fra en normalfordeling til at fastlÃ¦gge en acceptabel niveau af usikkerhed, og estimere usikkerheden pÃ¥ sine stikprÃ¸veberegninger!

------------------------------------------------------------------------

# Normalfordelingen og statistisk usikkerhed

Hvis en variabel er normalfordelt sÃ¥ ligger omkringâ€¦

-   68 % af observationerne i intervallet +/- 1 standardafvigelse fra middelvÃ¦rdien

-   95 % af observationerne i intervallet +/- 2 standardafvigelse fra middelvÃ¦rdien

-   99,7 % af observationerne i intervallet +/- 3 standardafvigelse fra middelvÃ¦rdien

------------------------------------------------------------------------

# Standardnormalfordeling

I praksis bruger man en sÃ¦rlig normalfordeling, nemlig ***standardnormalfordelingen***.

Hvorfor? Det er nemmest at tage udgangspunkt i en standardiseret udgave af normalfordelingen. Standardnormalfordelingen er en normalfordeling med et gennemsnit $\mu=0$ og en standardafvigelse $\sigma=1$

```{r}

# Load ggplot2 and grid (for arrows)
library(ggplot2)
library(grid)

# Parameters for the standard normal distribution
mean <- 0       # Mean (mu)
sd <- 1         # Standard deviation (sigma)

# Create a data frame with x values and their density for the normal distribution
x <- seq(-4, 4, length.out = 100)  # x-range
y <- dnorm(x, mean, sd)            # Density of the normal distribution
df <- data.frame(x, y)

# Plot the standard normal distribution
ggplot(df, aes(x = x, y = y)) +
  geom_line(color = "blue", size = 1) +
  labs(y = "SandsynlighedstÃ¦thed", x="Data") +
  theme_minimal() +
  
  # Add text for the mean and standard deviations, slightly shifted to the sides
  annotate("text", x = mean, y = max(y) + 0.02, label = expression(mu), size = 5, color = "black") +
  annotate("text", x = -1.3, y = dnorm(-1, mean, sd) + 0.02, label = expression(-sigma), size = 4, color = "black") +
  annotate("text", x = 1.3, y = dnorm(1, mean, sd) + 0.02, label = expression(sigma), size = 4, color = "black") +
  
  # Add a horizontal arrow between -sigma and +sigma, placed near the sd markers
  geom_segment(aes(x = -0.9, xend = .9, y = dnorm(1, mean, sd) + 0.01, yend = dnorm(1, mean, sd) + 0.01), 
               arrow = arrow(ends = "both", type = "closed", length = unit(0.2, "cm")), color = "black") +
annotate("text", x = 0, y = dnorm(1, mean, sd) + 0.03, label = "Â± Ïƒ", size = 4, color = "black")+
    theme(
    text = element_text(size = 16),            # General text size
    axis.title = element_text(size = 18),      # Axis title size
    axis.text = element_text(size = 14)      # Axis labels size
  )
```

------------------------------------------------------------------------

# Standardnormalfordeling

I standardnormalfordelingen ligger...

-   90 % af observationerne i intervallet Â±1,645 standardafvigelser fra middelvÃ¦rdien

-   95 % af observationerne i intervallet Â±1,96 standardafvigelser fra middelvÃ¦rdien

-   99 % af observationerne i intervallet Â±2,576 standardafvigelser fra middelvÃ¦rdien

------------------------------------------------------------------------

# Estimation i stikprÃ¸ver

NÃ¥r vi ikke har adgang til fuld population kan vi altsÃ¥ bruge stikprÃ¸ver til at estimere, hvordan fordelinger ser ud i populationen:

-   $\mu$: Populationsgennemsnittet (det sande gennemsnit for hele populationen).

-   $\bar{X}$: StikprÃ¸vegennemsnittet (gennemsnittet beregnet ud fra en stikprÃ¸ve, som bruges som et skÃ¸n for populationsgennemsnittet).

-   NÃ¥r stikprÃ¸ven er stor og reprÃ¦sentativ, kan vi antage at: $\bar{X} \approx \mu$

Dog mÃ¥ vi leve med, at der altid er en hvis usikkerhed forbundet med stikprÃ¸vegennemsnittet... til gengÃ¦ld kan vi bruge vores viden om normalfordelingen til at regne pÃ¥ den!

------------------------------------------------------------------------

# Konfidensintervaller

-   For at give et bud pÃ¥ den usikkerhed, der er forbundet med de beregninger vi laver pÃ¥ stikprÃ¸ver, kan vi udregne konfidensintervaller

-   Konfidensintervallet estimerer med en vis (u)sikkerhed indenfor hvilket interval populationens vÃ¦rdi ligger. I stedet for kun at angive et punkt-estimat (en andel eller et gennemsnittet), angiver man altsÃ¥ et interval inden for hvilket, man forventer at andelen/ gennemsnittet i populationen ligger.

------------------------------------------------------------------------

# Konfidensintervaller

-   Ved hjÃ¦lp af den standardnormalfordelingen kan vi beregne, hvor sandsynligt det er, at populationsgennemsnittet ligger i et bestemt interval omkring stikprÃ¸vegennemsnittet. Det er meget almindeligt at konstruere 95% konfidensintervaller.

-   Princippet er, at man sÃ¥ udregner et interval, hvor vi populationens vÃ¦rdi med 95 % sikkerhed ligger indenfor. For en normalfordeling svarer dette til $\pm 1.96$ standardafvigelser omkring stikprÃ¸vegennemsnittet.

------------------------------------------------------------------------

# Konfidensintervaller

![](images/standardnormalfordeling.png){fig-align="center"}

------------------------------------------------------------------------

# Konfidensintervaller: intervalskala

$$
u = 1,96 \cdot \frac{\sigma}{\sqrt{n}}
$$

-   $u$ = den statistiske usikkerhed

-   $\sigma$ = standardafvigelsen (vores beskrivende mÃ¥l fra tidligere)

-   $n$ = antal individer i stikprÃ¸ven $$
    \frac{\sigma}{\sqrt{n}} = \text{Standardfejlen (standard error â€“ beregnes pÃ¥ baggrund af standardafvigelsen)}
    $$

------------------------------------------------------------------------

# Konfidensintervaller: nominal og ordinal skala

$$
u = 1,96 \cdot \frac{p \cdot q}{n}
$$

-   $u$ = den statistiske usikkerhed\
-   $p$ = andel i den kategori vi gerne vil sige noget om\
-   $q$ = andel i variablens resterende kategorier\
-   $n$ = antal individer i stikprÃ¸ven

$$
\frac{p \cdot q}{n} = \text{Standardfejlen (standard error â€“ beregnes pÃ¥ baggrund af fordelingerne)}
$$

------------------------------------------------------------------------

# Statistisk usikkerhed og stikprÃ¸vestÃ¸rrelse

Hvor statistisk sikker er en stikprÃ¸ve?

-   StikprÃ¸ven absolutte stÃ¸rrelse: jo flere observationer desto bedre

-   StikprÃ¸vens stÃ¸rrelse ift. universets stÃ¸rrelse (udtrÃ¦k med tilbagelÃ¦gning?)

-   Variationen i universet

------------------------------------------------------------------------

# Statistisk usikkerhed og stikprÃ¸vestÃ¸rrelse

StikprÃ¸vens usikkerhed som funktion af stikprÃ¸vens stÃ¸rrelse:

::: table-slide
| n | 1/99% | 2/98% | 5/95% | 10/90% | 15/85% | 20/80% | 25/75% | 30/70% | 35/65% | 40/60% | 45/55% | 50/50% |
|------|------|------|------|------|------|------|------|------|------|------|------|------|
| 50 | 2,8% | 3,9% | 6,0% | 8,3% | 9,9% | 11,1% | 12,0% | 12,7% | 13,2% | 13,6% | 13,8% | 13,9% |
| 100 | 2,0% | 2,7% | 4,3% | 5,9% | 7,0% | 7,8% | 8,5% | 9,0% | 9,3% | 9,6% | 9,8% | 9,8% |
| 250 | 1,2% | 1,7% | 2,7% | 3,7% | 4,4% | 5,0% | 5,4% | 5,7% | 5,9% | 6,1% | 6,2% | 6,2% |
| 500 | 0,9% | 1,2% | 1,9% | 2,6% | 3,1% | 3,5% | 3,8% | 4,0% | 4,2% | 4,3% | 4,4% | 4,4% |
| 750 | 0,7% | 1,0% | 1,6% | 2,1% | 2,6% | 2,9% | 3,1% | 3,3% | 3,4% | 3,5% | 3,6% | 3,6% |
| 1.000 | 0,6% | 0,9% | 1,4% | 1,9% | 2,2% | 2,5% | 2,7% | 2,8% | 3,0% | 3,0% | 3,1% | 3,1% |
| 1.500 | 0,5% | 0,7% | 1,1% | 1,5% | 1,8% | 2,0% | 2,2% | 2,3% | 2,4% | 2,5% | 2,5% | 2,5% |
| 2.000 | 0,4% | 0,6% | 1,0% | 1,3% | 1,6% | 1,8% | 1,9% | 2,0% | 2,1% | 2,1% | 2,2% | 2,2% |
| 5.000 | 0,3% | 0,4% | 0,6% | 0,8% | 1,0% | 1,1% | 1,2% | 1,3% | 1,3% | 1,3% | 1,4% | 1,4% |
| 10.000 | 0,2% | 0,3% | 0,4% | 0,6% | 0,7% | 0,8% | 0,8% | 0,9% | 0,9% | 1,0% | 1,0% | 1,0% |
:::

------------------------------------------------------------------------

# Statistisk usikkerhed og stikprÃ¸vestÃ¸rrelse

Eksempel med 50/50 fordeling (hÃ¸j variation)

```{r}
# Load ggplot2 for plotting
library(ggplot2)

# Data from the table (sample sizes and uncertainty for 50/50 distribution)
data <- data.frame(
  N = c(50, 100, 250, 500, 750, 1000, 1500, 2000, 5000, 10000),
  Uncertainty = c(13.9, 9.8, 6.2, 4.4, 3.6, 3.1, 2.5, 2.2, 1.4, 1.0)
)

# Create line graph
ggplot(data, aes(x = N, y = Uncertainty)) +
  geom_line(color = "blue", size = 1) +
  scale_x_continuous(breaks = seq(0, 10000, by = 1000)) +  # Adds ticks every 500 units
  scale_y_continuous(breaks = seq(0, 15, by = 1)) +  # Adds ticks every 500 units
  labs(
    x = "StikprÃ¸vestÃ¸rrelse (N)",
    y = "Usikkerhed (%)"
  ) +
  theme_minimal() +
   theme(
    axis.title = element_text(size = 14),  # Increase axis titles font size
    axis.text = element_text(size = 12)    # Increase axis labels font size
  )
```

------------------------------------------------------------------------

# Statistisk usikkerhed og stikprÃ¸vestÃ¸rrelse

Eksempel med 1/99 fordeling (lav variation)

```{r}
# Data from the table (sample sizes and uncertainty for 1/99 distribution)
data <- data.frame(
  N = c(50, 100, 250, 500, 750, 1000, 1500, 2000, 5000, 10000),
  Uncertainty = c(2.8, 2.0, 1.2, 0.9, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2)
)

# Create line graph for 1/99 distribution
ggplot(data, aes(x = N, y = Uncertainty)) +
  geom_line(color = "blue", size = 1) +
  scale_x_continuous(breaks = seq(0, 10000, by = 1000)) +
  scale_y_continuous(breaks = seq(0, 3, by = 0.5)) +
  labs(
    x = "StikprÃ¸vestÃ¸rrelse (N)",
    y = "Usikkerhed (%)") +
  theme_minimal() +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12)
  )
```

------------------------------------------------------------------------

# ReprÃ¦sentativitet og bortfald

En reprÃ¦sentativ stikprÃ¸ve er en stikprÃ¸ve, som *reprÃ¦senterer* den population, som den er trukket fra pÃ¥ vÃ¦sentlige karakteristka. ReprÃ¦sentativitet afhÃ¦nger dels af:

<br>

-   UdvÃ¦lgelsesmekanismen (hvordan man trÃ¦kker sin stikprÃ¸ve)

-   SkÃ¦vhed i stikprÃ¸ven (sampling bias)

    -   TilfÃ¦ldig skÃ¦vhed (som udgangspunkt uproblematisk)

    -   Systematisk skÃ¦vhed: der er systematik i, hvem der svarer, og hvem der ikke gÃ¸r (problematisk!)

------------------------------------------------------------------------

# ReprÃ¦sentativitet og bortfald

## ![](images/studiepopulation.png)

------------------------------------------------------------------------

# ReprÃ¦sentativitet og bortfald

**Eks.**

*Hvilken form for skÃ¦vhed ville vi forvente, hvis vi udsendte en survey blandt en stikprÃ¸ve af borgere i GrÃ¸nland (simpelt tilfÃ¦ldigt udtrukket), men kun gjorde vores survey tilgÃ¦ngelig pÃ¥ dansk?*

------------------------------------------------------------------------

# ReprÃ¦sentativitet og bortfald

Bortfald er vigtigt, fordi det er pÃ¥virker vores undersÃ¸gelses eksterne validitet:

-   **Ekstern validitet:** Refererer til *generaliserbarheden* af resultaterne.

<br>

SpÃ¸rg dig selv: Kan du generalisere pÃ¥ dine resultater fra stikprÃ¸ven til den population, som stikprÃ¸ven kommer fra? Er populationen reprÃ¦senteret i tilstrÃ¦kkelig grad i stikprÃ¸ven? Det var jo hele pointen bag stikprÃ¸ven i fÃ¸rste omgang!

------------------------------------------------------------------------

# ReprÃ¦sentativitet og bortfald

Man kan finde ud af, om ens stikprÃ¸ve er reprÃ¦sentativ for populationen ved at sammenligne fordelinger pÃ¥ vigtige variable fra hhv. population og stikprÃ¸ve og evt. vÃ¦gte underreprÃ¦senterede grupper op:

::: table-slide
| KÃ¸n | Alder (Ã¥r) | Univers (antal) | Univers (pct.) | StikprÃ¸ve (antal) | StikprÃ¸ve (pct.) | VÃ¦gt |
|-----------|-----------|-----------|-----------|-----------|-----------|-----------|
| MÃ¦nd | 15-40 | 874.044 | 19,8 | 165 | 13,3 | 19,8/13,3=**1,49** |
| MÃ¦nd | 40-69 | 1.057.619 | 24,0 | 368 | 29,6 | 24/29,6=**0,81** |
| MÃ¦nd | 70+ | 233.798 | 5,3 | 77 | 6,2 | 5,3/6,2=**0,86** |
| Kvinder | 15-40 | 851.737 | 19,3 | 179 | 14,4 | 19,3/14,4=**1,34** |
| Kvinder | 40-69 | 1.053.420 | 23,9 | 359 | 28,9 | 23,9/28,9=**0,83** |
| Kvinder | 70+ | 340.962 | 7,7 | 96 | 7,7 | 7,7/7,7=**1** |
| **Total** |  | **4.411.580** | **100** | **1.244** | **100** |  |
:::

*Obs: her antages det, at der er tilfÃ¦ldigt bortfald! Ellers vÃ¦gter man bare skÃ¦vheden yderligere op.*

------------------------------------------------------------------------

# Niveauer

::: table-slide
| Begreb | Definition |
|---------------------------------------------|--------------------------|
| **Universet/populationen** | MÃ¥lgruppe, hvori en stikprÃ¸ve udtrÃ¦kkes (fx alle statsborgere i Danmark). |
| **Den mulige population** | Del af universet, som kan udtrÃ¦kkes til stikprÃ¸ven. |
| **StikprÃ¸ve/sample** | Lille del af universet, udvalgt til at reprÃ¦sentere hele universet. |
| **Respondenter/besvarelser** | Del af stikprÃ¸ven, der deltager i surveyen (svarprocent). |
:::

------------------------------------------------------------------------

## Opsamling: populationer og stikprÃ¸ver

-   **Population og stikprÃ¸ve**:
    -   En population er den gruppe, vi Ã¸nsker at undersÃ¸ge.
    -   En stikprÃ¸ve er en reprÃ¦sentativ del af populationen, som bruges til at drage konklusioner om populationen.

<br>

-   **ReprÃ¦sentativitet og bortfald**:
    -   En stikprÃ¸ve skal vÃ¦re reprÃ¦sentativ for populationen for at give gyldige resultater.
    -   TilfÃ¦ldig skÃ¦vhed kan tolereres, men systematisk skÃ¦vhed pÃ¥virker resultaterne negativt.

------------------------------------------------------------------------

## Opsamling: populationer og stikprÃ¸ver

-   **Statistisk usikkerhed og sandsynlighed**:
    -   Usikkerhed er altid til stede, nÃ¥r vi bruger stikprÃ¸ver.
    -   Store tals lov og den centrale grÃ¦nsevÃ¦rdisÃ¦tning sikrer, at stikprÃ¸vegennemsnit er pÃ¥lidelige estimater af populationsgennemsnit for store stikprÃ¸ver.

<br>

-   **Binomial- og normalfordeling**:
    -   Binomialfordelingen bruges til diskrete sandsynligheder (to udfald).
    -   Normalfordelingen bruges til kontinuerte variabler og er grundlaget for beregning af konfidensintervaller.

------------------------------------------------------------------------

## Opsamling: populationer og stikprÃ¸ver

-   **Konfidensintervaller**:
    -   Bruges til at give et interval omkring stikprÃ¸vegennemsnittet, hvor vi med hÃ¸j sandsynlighed forventer, at populationsgennemsnittet ligger.

<br>

-   **StikprÃ¸vestÃ¸rrelse og variation**:
    -   Jo stÃ¸rre stikprÃ¸ven er, jo lavere usikkerhed.
    -   Variation i populationen pÃ¥virker, hvor prÃ¦cis vores stikprÃ¸ve kan vÃ¦re med en given stÃ¸rrelse.
